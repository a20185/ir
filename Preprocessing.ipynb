{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#encoding=utf-8\n",
    "# 基本部件的引用声明\n",
    "import sys\n",
    "import re\n",
    "import codecs\n",
    "import os\n",
    "import shutil\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "import graphlab\n",
    "import numpy as np\n",
    "from array import array\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 注意我们这里需要安装好的依赖有Graphlab，numpy，jieba\n",
    "* Numpy和Jieba直接pip即可\n",
    "* Graphlab是商业软件，需要授权\n",
    "    * PIP安装时用此命令：(括号内可选)\n",
    "         * (sudo) pip install (--user) --upgrade --no-cache-dir https://get.graphlab.com/GraphLab-Create/2.0.1/ouyf5@mail2.sysu.edu.cn/F822-FCB4-973D-5C49-44E0-430C-BC81-4EA3/GraphLab-Create-License.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 首先是从文件中的读取以及分词\n",
    "\n",
    "\n",
    "此处用的是 *Jieba* 中文分词器，在这里我们将中文文本分词之后以空格分隔各词然后输出到目标文件夹\n",
    "\n",
    "函数定义中需传入 **CSV文件的绝对地址** \n",
    "\n",
    "格式要求：\n",
    "   * CSV中字串以UTF-8格式编码，CSV文件格式为id,content(需要有Header Row)\n",
    "   * 传入目标文件为绝对地址\n",
    "   * 获得的数据为SFrame格式，column与CSV格式一致\n",
    "   * SFrame参考文档：https://turi.com/products/create/docs/generated/graphlab.SFrame.html?highlight=sframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 首先是添加停词表（Stop Words List）\n",
    "* 加入停词表能够把常用的词语（通常是介词、连接词等）去掉，提高分类的准确性\n",
    "* get_stop_words 这个方法从文件中读取停词列表，然后返回一个 **停词集合**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_from_file(path):\n",
    "    with open(path,\"r\") as fp:\n",
    "        words = fp.read()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_stop_words(filepath):\n",
    "    words = read_from_file(filepath)\n",
    "    result = jieba.cut(words)\n",
    "    new_words = []\n",
    "    for r in result:\n",
    "        new_words.append(r)\n",
    "    return set(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_stop_words(words,stop_words_set):\n",
    "    new_words = []\n",
    "    for w in words:\n",
    "        if w not in stop_words_set:\n",
    "            new_words.append(w)\n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checkpoint: 检查上述方法的正确性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create is assigned to ouyf5@mail2.sysu.edu.cn and will expire on November 25, 2016. For commercial licensing options, visit https://turi.com/buy/.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.cython.cy_server: GraphLab Create v2.0.1 started. Logging: C:\\Users\\Tidyzq\\AppData\\Local\\Temp\\graphlab_server_1469086529.log.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"62,娆ф床鑸�ぉ灞�European Space Agency)灞�暱闊﹀皵绾�Johann-Dietrich Worner)绉帮紝灏界�缇庡浗鍥戒細浠嶅己鐑堝弽瀵癸紝浠栧凡鍐嶆�鎻愬嚭閭��涓�浗鍙備笌鍥介檯绌洪棿绔欓」鐩�殑鎯虫硶銆傞煢灏旂撼鍦ㄦ硶鎭╀集鍕掕埅灞曟湡闂存帴鍙楅噰璁挎椂琛ㄧず锛屼笉搴...\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"62,娆ф床鑸�ぉ灞�European Space Agency)灞�暱闊﹀皵绾�Johann-Dietrich Worner)绉帮紝灏界�缇庡浗鍥戒細浠嶅己鐑堝弽瀵癸紝浠栧凡鍐嶆�鎻愬嚭閭��涓�浗鍙備笌鍥介檯绌洪棿绔欓」鐩�殑鎯虫硶銆傞煢灏旂撼鍦ㄦ硶鎭╀集鍕掕埅灞曟湡闂存帴鍙楅噰璁挎椂琛ㄧず锛屼笉搴...\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"44,鐭ユ儏浜哄＋绉帮紝鏃ユ湰杞�摱闆嗗洟鑲′唤鏈夐檺鍏�徃(SoftBank Group Corp. ,9984.TO)宸茬粡鍚屾剰浠ュ叏鐜伴噾鏂瑰紡鏀惰喘鑻卞浗鑺�墖璁捐�鍏�徃ARM Holdings PLC (ARMH)锛岃�浜ゆ槗浠峰�瓒呰繃320浜跨編鍏冦�璇ョ煡鎯呬汉澹�О锛岄�璁¤繖妗╀氦鏄撳皢浜庡...\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"44,鐭ユ儏浜哄＋绉帮紝鏃ユ湰杞�摱闆嗗洟鑲′唤鏈夐檺鍏�徃(SoftBank Group Corp. ,9984.TO)宸茬粡鍚屾剰浠ュ叏鐜伴噾鏂瑰紡鏀惰喘鑻卞浗鑺�墖璁捐�鍏�徃ARM Holdings PLC (ARMH)锛岃�浜ゆ槗浠峰�瓒呰繃320浜跨編鍏冦�璇ョ煡鎯呬汉澹�О锛岄�璁¤繖妗╀氦鏄撳皢浜庡...\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>2 lines failed to parse correctly</pre>"
      ],
      "text/plain": [
       "2 lines failed to parse correctly"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file G:\\workspace\\ir\\data.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file G:\\workspace\\ir\\data.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[long,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 98 lines in 0.014017 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 98 lines in 0.014017 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"62,娆ф床鑸�ぉ灞�European Space Agency)灞�暱闊﹀皵绾�Johann-Dietrich Worner)绉帮紝灏界�缇庡浗鍥戒細浠嶅己鐑堝弽瀵癸紝浠栧凡鍐嶆�鎻愬嚭閭��涓�浗鍙備笌鍥介檯绌洪棿绔欓」鐩�殑鎯虫硶銆傞煢灏旂撼鍦ㄦ硶鎭╀集鍕掕埅灞曟湡闂存帴鍙楅噰璁挎椂琛ㄧず锛屼笉搴...\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"62,娆ф床鑸�ぉ灞�European Space Agency)灞�暱闊﹀皵绾�Johann-Dietrich Worner)绉帮紝灏界�缇庡浗鍥戒細浠嶅己鐑堝弽瀵癸紝浠栧凡鍐嶆�鎻愬嚭閭��涓�浗鍙備笌鍥介檯绌洪棿绔欓」鐩�殑鎯虫硶銆傞煢灏旂撼鍦ㄦ硶鎭╀集鍕掕埅灞曟湡闂存帴鍙楅噰璁挎椂琛ㄧず锛屼笉搴...\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"44,鐭ユ儏浜哄＋绉帮紝鏃ユ湰杞�摱闆嗗洟鑲′唤鏈夐檺鍏�徃(SoftBank Group Corp. ,9984.TO)宸茬粡鍚屾剰浠ュ叏鐜伴噾鏂瑰紡鏀惰喘鑻卞浗鑺�墖璁捐�鍏�徃ARM Holdings PLC (ARMH)锛岃�浜ゆ槗浠峰�瓒呰繃320浜跨編鍏冦�璇ョ煡鎯呬汉澹�О锛岄�璁¤繖妗╀氦鏄撳皢浜庡...\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"44,鐭ユ儏浜哄＋绉帮紝鏃ユ湰杞�摱闆嗗洟鑲′唤鏈夐檺鍏�徃(SoftBank Group Corp. ,9984.TO)宸茬粡鍚屾剰浠ュ叏鐜伴噾鏂瑰紡鏀惰喘鑻卞浗鑺�墖璁捐�鍏�徃ARM Holdings PLC (ARMH)锛岃�浜ゆ槗浠峰�瓒呰繃320浜跨編鍏冦�璇ョ煡鎯呬汉澹�О锛岄�璁¤繖妗╀氦鏄撳皢浜庡...\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>2 lines failed to parse correctly</pre>"
      ],
      "text/plain": [
       "2 lines failed to parse correctly"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file G:\\workspace\\ir\\data.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file G:\\workspace\\ir\\data.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 98 lines in 0.014013 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 98 lines in 0.014013 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache c:\\users\\tidyzq\\appdata\\local\\temp\\jieba.cache\n",
      "Loading model cost 1.990 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Runtime Exception. Column name text does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-e861df7afb14>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#    print lister[i]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mweibo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_and_cut\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./data.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;31m#print weibo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-f39a9246dd5a>\u001b[0m in \u001b[0;36mread_and_cut\u001b[1;34m(csvpath)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmydata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0municode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmydata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mseglist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjieba\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcut\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mcut_all\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mparsed_seg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mremove_stop_words\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseglist\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mstop_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Tidyzq\\Anaconda2\\envs\\gl-env\\lib\\site-packages\\graphlab\\data_structures\\sframe.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3997\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_row_selector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3998\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3999\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4000\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4001\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect_columns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Tidyzq\\Anaconda2\\envs\\gl-env\\lib\\site-packages\\graphlab\\data_structures\\sframe.pyc\u001b[0m in \u001b[0;36mselect_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3600\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid key type: must be str\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3601\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mcython_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3602\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mSArray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_proxy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__proxy__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3603\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3604\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mselect_columns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeylist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Tidyzq\\Anaconda2\\envs\\gl-env\\lib\\site-packages\\graphlab\\cython\\context.pyc\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow_cython_trace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m                 \u001b[1;31m# To hide cython trace, we re-raise from here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m                 \u001b[1;31m# To show the full trace, we do nothing and let exception propagate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Runtime Exception. Column name text does not exist."
     ]
    }
   ],
   "source": [
    "#stop_set = get_stop_words('./stop.txt')\n",
    "#lister = list(stop_set)\n",
    "#for i in range(10):\n",
    "#    print lister[i]\n",
    "\n",
    "weibo = read_and_cut('./data.csv')\n",
    "#print weibo\n",
    "\n",
    "train_fake_news = weibo[0:10]\n",
    "train_fake_weibos = weibo[10:]\n",
    "\n",
    "weibos_wvec = batch_word_vec_generator(train_fake_weibos['parsed'] , True)\n",
    "news_wvec = batch_word_vec_generator(train_fake_news['parsed'] , True)\n",
    "\n",
    "\n",
    "train_fake_news['word_vec'] = news_wvec['word_vec']\n",
    "train_fake_news['tf_word_vec'] = news_wvec['tf_word_vec']\n",
    "train_fake_news['assign_weibos'] = batch_NN_finder(train_fake_news['tf_word_vec'] , weibos_wvec['tf_word_vec'] , train_fake_weibos['Id'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 下面是正式操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_and_cut(csvpath):\n",
    "    mydata = graphlab.SFrame(csvpath)\n",
    "    stop_set = get_stop_words('./stop.txt')\n",
    "    parsed = []\n",
    "    linen = {0,1,2,3,4,5,6,7,8,9,19,39,59,99,399,599,999,2999,3999,5999,8888,9999}\n",
    "    \n",
    "    for i in range(len(mydata)):\n",
    "        line = unicode(mydata['text'][i] , \"utf-8\")\n",
    "        seglist = jieba.cut(line , cut_all = False)\n",
    "        parsed_seg = remove_stop_words(seglist , stop_set)\n",
    "        output = ' '.join(parsed_seg)\n",
    "        parsed.append(output)\n",
    "        if (i in linen or i == len(mydata) - 1):\n",
    "            print \"处理 #%d 文章完成\" % i\n",
    "    mydata['parsed'] = parsed\n",
    "    print \"全部完成！\"\n",
    "    return mydata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 接下来这个函数是用来提取*词数向量*的\n",
    "\n",
    "* 在分析过程中，可以频繁的调用该函数，需要提供 **原始文本的字串**\n",
    "* 返回值为一个 *Dict<单词，出现次数>* ,\n",
    "* 返回的Dict没有依据单词出现的次数排序\n",
    "* 如果用向量实现并不现实，所以在此处我们使用Dict来实现词数向量的功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_word_vec(ref_str):\n",
    "    words = [w.strip() for w in ref_str.split() if w.strip()]\n",
    "    counter = Counter()\n",
    "    for w in words:\n",
    "        counter[w] += 1\n",
    "    # kv = counter.items()   #这是键值对的列表\n",
    "    wc_dict = dict(counter)    #这是词典\n",
    "    #可以用列表做其他事，但只返回词典\n",
    "    return wc_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 接下来是计算两个词数向量间的距离\n",
    "\n",
    "* euc_dist 计算两个词数向量之间的欧几里得距离 返回值为浮点数\n",
    "* cos_dist 计算两个词数向量之间的余弦距离 返回值为浮点数\n",
    "* jac_dist 计算两个词数向量之间的加权杰卡德距离 返回值为浮点数\n",
    "\n",
    "注意到，此处只是使用计算距离对词数向量进行Brute-Force计算，很容易把一些常见的词错误的认为是判断两个文本文档相类似的函数的主要依据（如 **\"的\"** , **\"和\"** , **\"是\"**  , **\"了\"**  , etc）。如果需要计算更精确的数值，应该使用 **TF-IDF** 来进行计算,使用者在使用前应该调用 *calc_tf_idf* 方法。总体来说，即便使用TFIDF处理过，中文文本的聚类正确率还是不是非常的理想。所以可以尽情尝试各种距离（经过初步实验，Euclidean Distance准确度稍微高那么一点点。）\n",
    "\n",
    "* 注意, *calc_tf_idf* 方法需要使用者传入所有文本（whole documents）的 **SArray词典集合（SArray of dict）** 返回值为SArray的词典集合类型（每行分别为原来单词的dict的SArray集合）。(SArray文档：https://turi.com/products/create/docs/generated/graphlab.SArray.html?highlight=sarray)\n",
    "* 示例使用方法：\n",
    "    ```python\n",
    "        docs['TF_IDF'] = calc_tf_idf(docs['wc_dict'])\n",
    "    ```\n",
    "    这样处理之后还是可以通过\n",
    "    ```python\n",
    "    docs[docs['dName'] == 'docnamehere'][0]\n",
    "    ```\n",
    "    找到某行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def euc_dist(dict_a , dict_b):\n",
    "    return graphlab.distances.euclidean(dict_a , dict_b)\n",
    "\n",
    "def cos_dist(dict_a , dict_b):\n",
    "    return graphlab.distances.cosine(dict_a , dict_b)\n",
    "\n",
    "def jac_dist(dict_a , dict_b):\n",
    "    return graphlab.distances.weighted_jaccard(dict_a , dict_b)\n",
    "\n",
    "def calc_tf_idf(whole_document_dict):\n",
    "    return graphlab.text_analytics.tf_idf(whole_document_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 给某一个特定的新闻找到10个左右Nearnest Neighbour\n",
    "\n",
    "由于我们在数据库中存放的是微博，所以我们简单的给定 *新闻文档* ，然后给其适配最适合的10个微博。\n",
    "* 距离此处使用了欧式距离。\n",
    "* 初始阈值设定为50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 不管传入的是否是TF-IDF，要求传的新闻词数向量为Dictionary，whole_document_vec为dict的SFrame\n",
    "def find_NN(news_vec , whole_document_vec , doc_ids):\n",
    "    process_vec = graphlab.SFrame()\n",
    "    #process_vec['original'] = whole_document_vec\n",
    "    result_value = []\n",
    "    result_id = []\n",
    "\n",
    "    for i in range(len(whole_document_vec)):\n",
    "        cos_val = euc_dist(whole_document_vec[i] , news_vec)\n",
    "        if cos_val <= 200:\n",
    "            result_id.append(doc_ids[i])\n",
    "            result_value.append(cos_val)\n",
    "    process_vec['similarity'] = result_value\n",
    "    process_vec['id'] = result_id\n",
    "\n",
    "    my = process_vec.sort('similarity' , ascending=True)\n",
    "\n",
    "    if len(process_vec) < 10:\n",
    "        return my\n",
    "    else:\n",
    "        return my[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 批量生成工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_word_vec_generator(dict_set , TF_SELECTOR = False):\n",
    "        gen_result = graphlab.SFrame()\n",
    "        word_vec = []\n",
    "        linen = {0,1,2,3,4,5,6,7,8,9,19,39,59,99,399,599,999,2999,3999,5999,8888,9999}\n",
    "        for i in range(len(dict_set)):\n",
    "                temp_vec = parse_word_vec(dict_set[i])\n",
    "                word_vec.append(temp_vec)\n",
    "                if i in linen or i == len(dict_set) - 1:\n",
    "                    print \"第 %d 条文章原始词向量计算完成\" % i\n",
    "        gen_result['word_vec'] = word_vec\n",
    "        print \"本数据集的原始词向量全部计算完成\"\n",
    "        if TF_SELECTOR:\n",
    "                gen_result['tf_word_vec'] = calc_tf_idf(gen_result['word_vec'])\n",
    "                print \"本数据集的TF-IDF词向量全部计算完成\"\n",
    "        return gen_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_NN_finder(news , weibos , weibo_ids):\n",
    "    linen = {0,1,2,3,4,5,6,7,8,9,19,39,59,99,399,599,999,2999,3999,5999,8888,9999}\n",
    "    assignation = []\n",
    "    for i in range(len(news)):\n",
    "        temp_nns = find_NN(news[i] , weibos , weibo_ids)\n",
    "        assignation.append(temp_nns)\n",
    "        if i in linen or i == len(news) - 1:\n",
    "            print \"第 %d 条新闻的最近邻居计算完成\" % (i + 1)\n",
    "    return assignation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 函数测试完成，下面是预处理总方法\n",
    "\n",
    "由于我们需要的是新闻AND ITS 匹配微博\n",
    "所以本方法只返回一个SFrame，列为 <*新闻ID* , *新闻原文* , *新闻原始词向量* ,*tf词向量* ,*匹配微博* >\n",
    "\n",
    "注意：**匹配微博**为一个对象，其中含有匹配微博的< *id* , *相似度*>\n",
    "\n",
    "\n",
    "接受的参数为：\n",
    "* weibo_src: 微博CSV文件的绝对路径\n",
    "* news_src: 新闻CSV文件的绝对路径\n",
    "* TF_SELECTOR: TF-IDF选择子，表示是否需要进行TF词向量计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Main process\n",
    "#Result contains a SFrame that contains news raw word_vec and matching weibo\n",
    "def pre_process(weibo_src , news_src , TF_SELECTOR=False):\n",
    "    #分别处理微博和新闻\n",
    "    weibos = read_and_cut(weibo_src)\n",
    "    news = read_and_cut(news_src)\n",
    "    \n",
    "    #计算词向量和TF词向量\n",
    "    weibos_wvec = batch_word_vec_generator(weibos['parsed'] , TF_SELECTOR)\n",
    "    news_wvec = batch_word_vec_generator(news['parsed'] , TF_SELECTOR)\n",
    "    \n",
    "    news['word_vec'] = news_wvec['word_vec']\n",
    "    \n",
    "    if TF_SELECTOR:\n",
    "        news['tf_word_vec'] = news_wvec['tf_word_vec']\n",
    "        news['assign_weibos'] = batch_NN_finder(news['tf_word_vec'] , weibos_wvec['tf_word_vec'] , weibos['id'])\n",
    "    else:\n",
    "        news['assign_weibos'] = batch_NN_finder(news['word_vec'] , weibos_wvec['word_vec'] , weibos['id'])\n",
    "    \n",
    "    return news,weibos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"http://t.cn/R5aHrrR\"\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"http://t.cn/R5aHrrR\"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"http://t.cn/R5cTRG0浣犳�涔堢湅锛�\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"http://t.cn/R5cTRG0浣犳�涔堢湅锛�\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"http://t.cn/R5UWWXX\"\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"http://t.cn/R5UWWXX\"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"http://t.cn/R55WxAd\"\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"http://t.cn/R55WxAd\"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"http://t.cn/R55YTvx\"\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"http://t.cn/R55YTvx\"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"http://t.cn/R5crvhe\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"http://t.cn/R5crvhe\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"http://t.cn/R5cRGQN\"\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"http://t.cn/R5cRGQN\"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"http://t.cn/R5crb0r\"\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"http://t.cn/R5crb0r\"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"http://t.cn/R55uIb1\"\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"http://t.cn/R55uIb1\"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"http://t.cn/R5YEL0c\"\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"http://t.cn/R5YEL0c\"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>52 lines failed to parse correctly</pre>"
      ],
      "text/plain": [
       "52 lines failed to parse correctly"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file G:\\workspace\\ir\\weibo.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file G:\\workspace\\ir\\weibo.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.023022 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.023022 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[long,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"http://t.cn/R5aHrrR\"\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"http://t.cn/R5aHrrR\"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"http://t.cn/R5UWWXX\"\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"http://t.cn/R5UWWXX\"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"http://t.cn/R5cTRG0浣犳�涔堢湅锛�\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"http://t.cn/R5cTRG0浣犳�涔堢湅锛�\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"http://t.cn/R55WxAd\"\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"http://t.cn/R55WxAd\"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"http://t.cn/R55YTvx\"\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"http://t.cn/R55YTvx\"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"浠栫殑寤鸿�寰楀埌浜嗕縿缃楁柉缁忔祹鐣屽拰瀛︾晫鐨勬�杩庯細鈥滆祴鑳戒腑灏忎紒涓氱殑鎬濇兂锛屼細涓轰縿缃楁柉缁忔祹鎵惧埌鏂扮殑鍔ㄥ姏銆傗�http://t.cn/R5SAdm7\"\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"浠栫殑寤鸿�寰楀埌浜嗕縿缃楁柉缁忔祹鐣屽拰瀛︾晫鐨勬�杩庯細鈥滆祴鑳戒腑灏忎紒涓氱殑鎬濇兂锛屼細涓轰縿缃楁柉缁忔祹鎵惧埌鏂扮殑鍔ㄥ姏銆傗�http://t.cn/R5SAdm7\"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"http://t.cn/R55uIb1\"\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"http://t.cn/R55uIb1\"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"http://t.cn/R5crvhe\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"http://t.cn/R5crvhe\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"http://t.cn/R5cRGQN\"\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"http://t.cn/R5cRGQN\"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"http://t.cn/R5crb0r\"\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"http://t.cn/R5crb0r\"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>52 lines failed to parse correctly</pre>"
      ],
      "text/plain": [
       "52 lines failed to parse correctly"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file G:\\workspace\\ir\\weibo.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file G:\\workspace\\ir\\weibo.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 4379 lines in 0.030036 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 4379 lines in 0.030036 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理 #0 文章完成\n",
      "处理 #1 文章完成\n",
      "处理 #2 文章完成\n",
      "处理 #3 文章完成\n",
      "处理 #4 文章完成\n",
      "处理 #5 文章完成\n",
      "处理 #6 文章完成\n",
      "处理 #7 文章完成\n",
      "处理 #8 文章完成\n",
      "处理 #9 文章完成\n",
      "处理 #19 文章完成\n",
      "处理 #39 文章完成\n",
      "处理 #59 文章完成\n",
      "处理 #99 文章完成\n",
      "处理 #399 文章完成\n",
      "处理 #599 文章完成\n",
      "处理 #999 文章完成\n",
      "处理 #2999 文章完成\n",
      "处理 #3999 文章完成\n",
      "处理 #4378 文章完成\n",
      "全部完成！\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"聽 聽聽\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"聽 聽聽\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"...                                  缇庡浗鑻遍泟涓讳箟鐨勫吀鑼冧箣浣滃嵆渚垮湪浠婃棩鐪嬫潵銆婄嫭绔嬫棩銆嬬殑鐢靛奖鐗规晥闅句互璋堝緱涓婃儕鑹筹紝浣嗕笉鍙�惁璁ゅ湪褰撴椂鐨勬妧鏈�潯浠朵笅锛屻�鐙�珛鏃ャ�纭�綋灞炵數褰卞伐涓氬彂灞曚竴閮ㄤ护浜洪渿鎾肩殑閲�..\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"...                                  缇庡浗鑻遍泟涓讳箟鐨勫吀鑼冧箣浣滃嵆渚垮湪浠婃棩鐪嬫潵銆婄嫭绔嬫棩銆嬬殑鐢靛奖鐗规晥闅句互璋堝緱涓婃儕鑹筹紝浣嗕笉鍙�惁璁ゅ湪褰撴椂鐨勬妧鏈�潯浠朵笅锛屻�鐙�珛鏃ャ�纭�綋灞炵數褰卞伐涓氬彂灞曚竴閮ㄤ护浜洪渿鎾肩殑閲�..\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"\t鏈�悗涓��锛屸�涓嬭�鈥濓紝鈥滆捣绔嬧�锛屸�鑰佸笀鍐嶈�鈥濓紝鈥溾�鈥︹�锛岃�甯堟病鏈夎�鈥滃悓瀛︿滑鍐嶈�鈥濓紝鍙�槸绔欏湪閭ｉ噷鐪嬩簡鎴戜滑濂戒箙锛屾垜浠�篃娌℃湁鍧愪笅銆傛渶鍚庝竴璇撅紝鑰佺彮寮�帺绗戠殑璇粹�绂讳笅璇捐繕鏈�鍒嗛挓锛屾垜鍐嶅�..\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"\t鏈�悗涓��锛屸�涓嬭�鈥濓紝鈥滆捣绔嬧�锛屸�鑰佸笀鍐嶈�鈥濓紝鈥溾�鈥︹�锛岃�甯堟病鏈夎�鈥滃悓瀛︿滑鍐嶈�鈥濓紝鍙�槸绔欏湪閭ｉ噷鐪嬩簡鎴戜滑濂戒箙锛屾垜浠�篃娌℃湁鍧愪笅銆傛渶鍚庝竴璇撅紝鑰佺彮寮�帺绗戠殑璇粹�绂讳笅璇捐繕鏈�鍒嗛挓锛屾垜鍐嶅�..\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"@娓℃浮楦焒锛氭渶鍚庝竴鑺傝嚜涔犺�锛岀彮涓讳换鍦ㄥ墠闈㈢湅鑷�範锛屾暟瀛﹁�甯堟�鍖嗗寙澶圭潃鍗峰瓙杩涙潵锛屸�鍚屽�浠�敞鎰忎竴涓嬶紝鎴戜及璁¤繖涓�叕寮忎細鑰冣�锛屽氨鏄�繖涓��甯堬紝楂樹腑涓夊勾涓嶇煡閬撶敤浜嗘垜浠��灏戣嚜涔犺�鑰冭瘯璁插嵎瀛愶�..\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"@娓℃浮楦焒锛氭渶鍚庝竴鑺傝嚜涔犺�锛岀彮涓讳换鍦ㄥ墠闈㈢湅鑷�範锛屾暟瀛﹁�甯堟�鍖嗗寙澶圭潃鍗峰瓙杩涙潵锛屸�鍚屽�浠�敞鎰忎竴涓嬶紝鎴戜及璁¤繖涓�叕寮忎細鑰冣�锛屽氨鏄�繖涓��甯堬紝楂樹腑涓夊勾涓嶇煡閬撶敤浜嗘垜浠��灏戣嚜涔犺�鑰冭瘯璁插嵎瀛愶�..\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"鏉ユ簮锛氬ぇ娌冲�鎴风�缁煎悎鐝�富浠荤爺绌朵細銆佽眴鐡ｇ瓑\"\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"鏉ユ簮锛氬ぇ娌冲�鎴风�缁煎悎鐝�富浠荤爺绌朵細銆佽眴鐡ｇ瓑\"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"        绮ゅ叕缃戝畨澶�44010402000035鍙�\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"        绮ゅ叕缃戝畨澶�44010402000035鍙�\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"        涓荤�锛氫腑鍏辨箹鍖楃渷濮斿�浼犻儴 婀栧寳鐪佷汉姘戞斂搴滄柊闂诲姙鍏��銆�富鍔烇細婀栧寳鏃ユ姤浼犲獟闆嗗洟锛堟箹鍖楁棩鎶ョぞ锛壜犱富绠★細涓�叡婀栧寳鐪佸�瀹ｄ紶閮�婀栧寳鐪佷汉姘戞斂搴滄柊闂诲姙鍏��銆�富鍔烇細婀栧寳鏃ユ姤浼犲獟闆嗗洟锛堟箹�..\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"        涓荤�锛氫腑鍏辨箹鍖楃渷濮斿�浼犻儴 婀栧寳鐪佷汉姘戞斂搴滄柊闂诲姙鍏��銆�富鍔烇細婀栧寳鏃ユ姤浼犲獟闆嗗洟锛堟箹鍖楁棩鎶ョぞ锛壜犱富绠★細涓�叡婀栧寳鐪佸�瀹ｄ紶閮�婀栧寳鐪佷汉姘戞斂搴滄柊闂诲姙鍏��銆�富鍔烇細婀栧寳鏃ユ姤浼犲獟闆嗗洟锛堟箹�..\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"        绮ゅ叕缃戝畨澶�44010402000035鍙�\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"        绮ゅ叕缃戝畨澶�44010402000035鍙�\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"        涓荤�锛氫腑鍏辨箹鍖楃渷濮斿�浼犻儴 婀栧寳鐪佷汉姘戞斂搴滄柊闂诲姙鍏��銆�富鍔烇細婀栧寳鏃ユ姤浼犲獟闆嗗洟锛堟箹鍖楁棩鎶ョぞ锛壜犱富绠★細涓�叡婀栧寳鐪佸�瀹ｄ紶閮�婀栧寳鐪佷汉姘戞斂搴滄柊闂诲姙鍏��銆�富鍔烇細婀栧寳鏃ユ姤浼犲獟闆嗗洟锛堟箹�..\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"        涓荤�锛氫腑鍏辨箹鍖楃渷濮斿�浼犻儴 婀栧寳鐪佷汉姘戞斂搴滄柊闂诲姙鍏��銆�富鍔烇細婀栧寳鏃ユ姤浼犲獟闆嗗洟锛堟箹鍖楁棩鎶ョぞ锛壜犱富绠★細涓�叡婀栧寳鐪佸�瀹ｄ紶閮�婀栧寳鐪佷汉姘戞斂搴滄柊闂诲姙鍏��銆�富鍔烇細婀栧寳鏃ユ姤浼犲獟闆嗗洟锛堟箹�..\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"          鏈烘瀯鐪嬪競锛氫笅鍗婂勾閲忚穼浠锋定 涓�暱鏈熸嫄鐐瑰凡鑷冲墠5鏈堟ゼ甯傛垚浜ゅ�閫熷嚭鐜颁笅婊戯紝浼间箮棰勭ず鐫�湰杞�懆鏈熷凡浠庨《鐐硅穼钀姐�杩戞棩锛屽�瀹舵満鏋勫彂甯冪瓥鐣ユ姤鍛婏紝瀵逛笅鍗婂勾妤煎競杩涜�棰勫垽銆傚ぇ閮ㄥ垎鏈烘瀯璁や负锛屾...\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"          鏈烘瀯鐪嬪競锛氫笅鍗婂勾閲忚穼浠锋定 涓�暱鏈熸嫄鐐瑰凡鑷冲墠5鏈堟ゼ甯傛垚浜ゅ�閫熷嚭鐜颁笅婊戯紝浼间箮棰勭ず鐫�湰杞�懆鏈熷凡浠庨《鐐硅穼钀姐�杩戞棩锛屽�瀹舵満鏋勫彂甯冪瓥鐣ユ姤鍛婏紝瀵逛笅鍗婂勾妤煎競杩涜�棰勫垽銆傚ぇ閮ㄥ垎鏈烘瀯璁や负锛屾...\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>183 lines failed to parse correctly</pre>"
      ],
      "text/plain": [
       "183 lines failed to parse correctly"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file G:\\workspace\\ir\\news.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file G:\\workspace\\ir\\news.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.037038 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.037038 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"\t鏈�悗涓��锛屸�涓嬭�鈥濓紝鈥滆捣绔嬧�锛屸�鑰佸笀鍐嶈�鈥濓紝鈥溾�鈥︹�锛岃�甯堟病鏈夎�鈥滃悓瀛︿滑鍐嶈�鈥濓紝鍙�槸绔欏湪閭ｉ噷鐪嬩簡鎴戜滑濂戒箙锛屾垜浠�篃娌℃湁鍧愪笅銆傛渶鍚庝竴璇撅紝鑰佺彮寮�帺绗戠殑璇粹�绂讳笅璇捐繕鏈�鍒嗛挓锛屾垜鍐嶅�..\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"\t鏈�悗涓��锛屸�涓嬭�鈥濓紝鈥滆捣绔嬧�锛屸�鑰佸笀鍐嶈�鈥濓紝鈥溾�鈥︹�锛岃�甯堟病鏈夎�鈥滃悓瀛︿滑鍐嶈�鈥濓紝鍙�槸绔欏湪閭ｉ噷鐪嬩簡鎴戜滑濂戒箙锛屾垜浠�篃娌℃湁鍧愪笅銆傛渶鍚庝竴璇撅紝鑰佺彮寮�帺绗戠殑璇粹�绂讳笅璇捐繕鏈�鍒嗛挓锛屾垜鍐嶅�..\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"@娓℃浮楦焒锛氭渶鍚庝竴鑺傝嚜涔犺�锛岀彮涓讳换鍦ㄥ墠闈㈢湅鑷�範锛屾暟瀛﹁�甯堟�鍖嗗寙澶圭潃鍗峰瓙杩涙潵锛屸�鍚屽�浠�敞鎰忎竴涓嬶紝鎴戜及璁¤繖涓�叕寮忎細鑰冣�锛屽氨鏄�繖涓��甯堬紝楂樹腑涓夊勾涓嶇煡閬撶敤浜嗘垜浠��灏戣嚜涔犺�鑰冭瘯璁插嵎瀛愶�..\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"@娓℃浮楦焒锛氭渶鍚庝竴鑺傝嚜涔犺�锛岀彮涓讳换鍦ㄥ墠闈㈢湅鑷�範锛屾暟瀛﹁�甯堟�鍖嗗寙澶圭潃鍗峰瓙杩涙潵锛屸�鍚屽�浠�敞鎰忎竴涓嬶紝鎴戜及璁¤繖涓�叕寮忎細鑰冣�锛屽氨鏄�繖涓��甯堬紝楂樹腑涓夊勾涓嶇煡閬撶敤浜嗘垜浠��灏戣嚜涔犺�鑰冭瘯璁插嵎瀛愶�..\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"鏉ユ簮锛氬ぇ娌冲�鎴风�缁煎悎鐝�富浠荤爺绌朵細銆佽眴鐡ｇ瓑\"\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"鏉ユ簮锛氬ぇ娌冲�鎴风�缁煎悎鐝�富浠荤爺绌朵細銆佽眴鐡ｇ瓑\"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"        绮ゅ叕缃戝畨澶�44010402000035鍙�\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"        绮ゅ叕缃戝畨澶�44010402000035鍙�\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"        涓荤�锛氫腑鍏辨箹鍖楃渷濮斿�浼犻儴 婀栧寳鐪佷汉姘戞斂搴滄柊闂诲姙鍏��銆�富鍔烇細婀栧寳鏃ユ姤浼犲獟闆嗗洟锛堟箹鍖楁棩鎶ョぞ锛壜犱富绠★細涓�叡婀栧寳鐪佸�瀹ｄ紶閮�婀栧寳鐪佷汉姘戞斂搴滄柊闂诲姙鍏��銆�富鍔烇細婀栧寳鏃ユ姤浼犲獟闆嗗洟锛堟箹�..\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"        涓荤�锛氫腑鍏辨箹鍖楃渷濮斿�浼犻儴 婀栧寳鐪佷汉姘戞斂搴滄柊闂诲姙鍏��銆�富鍔烇細婀栧寳鏃ユ姤浼犲獟闆嗗洟锛堟箹鍖楁棩鎶ョぞ锛壜犱富绠★細涓�叡婀栧寳鐪佸�瀹ｄ紶閮�婀栧寳鐪佷汉姘戞斂搴滄柊闂诲姙鍏��銆�富鍔烇細婀栧寳鏃ユ姤浼犲獟闆嗗洟锛堟箹�..\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"聽 聽聽\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"聽 聽聽\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"        涓荤�锛氫腑鍏辨箹鍖楃渷濮斿�浼犻儴 婀栧寳鐪佷汉姘戞斂搴滄柊闂诲姙鍏��銆�富鍔烇細婀栧寳鏃ユ姤浼犲獟闆嗗洟锛堟箹鍖楁棩鎶ョぞ锛壜犱富绠★細涓�叡婀栧寳鐪佸�瀹ｄ紶閮�婀栧寳鐪佷汉姘戞斂搴滄柊闂诲姙鍏��銆�富鍔烇細婀栧寳鏃ユ姤浼犲獟闆嗗洟锛堟箹�..\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"        涓荤�锛氫腑鍏辨箹鍖楃渷濮斿�浼犻儴 婀栧寳鐪佷汉姘戞斂搴滄柊闂诲姙鍏��銆�富鍔烇細婀栧寳鏃ユ姤浼犲獟闆嗗洟锛堟箹鍖楁棩鎶ョぞ锛壜犱富绠★細涓�叡婀栧寳鐪佸�瀹ｄ紶閮�婀栧寳鐪佷汉姘戞斂搴滄柊闂诲姙鍏��銆�富鍔烇細婀栧寳鏃ユ姤浼犲獟闆嗗洟锛堟箹�..\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"          浠婃棩锛�4鏃ワ級涓嬪崍锛岃嫳鍥借劚娆у凡鎴愪簨瀹烇紝閬块櫓璧勪骇榛勯噾浠锋牸鍐查珮鍥炶惤銆傛埅鑷宠�鑰呭彂绋挎椂锛岄粍閲戜环鏍间綅浜�320缇庡厓/鐩庡徃锛屾定骞呯害涓�.20%銆傜敱浜庨伩闄╂儏缁�績鍙戦粍閲戜环鏍煎法澶ф尝鍔�紝榛勯噾鏈熻揣浠锋牸鐩�..\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"          浠婃棩锛�4鏃ワ級涓嬪崍锛岃嫳鍥借劚娆у凡鎴愪簨瀹烇紝閬块櫓璧勪骇榛勯噾浠锋牸鍐查珮鍥炶惤銆傛埅鑷宠�鑰呭彂绋挎椂锛岄粍閲戜环鏍间綅浜�320缇庡厓/鐩庡徃锛屾定骞呯害涓�.20%銆傜敱浜庨伩闄╂儏缁�績鍙戦粍閲戜环鏍煎法澶ф尝鍔�紝榛勯噾鏈熻揣浠锋牸鐩�..\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"...                                  缇庡浗鑻遍泟涓讳箟鐨勫吀鑼冧箣浣滃嵆渚垮湪浠婃棩鐪嬫潵銆婄嫭绔嬫棩銆嬬殑鐢靛奖鐗规晥闅句互璋堝緱涓婃儕鑹筹紝浣嗕笉鍙�惁璁ゅ湪褰撴椂鐨勬妧鏈�潯浠朵笅锛屻�鐙�珛鏃ャ�纭�綋灞炵數褰卞伐涓氬彂灞曚竴閮ㄤ护浜洪渿鎾肩殑閲�..\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"...                                  缇庡浗鑻遍泟涓讳箟鐨勫吀鑼冧箣浣滃嵆渚垮湪浠婃棩鐪嬫潵銆婄嫭绔嬫棩銆嬬殑鐢靛奖鐗规晥闅句互璋堝緱涓婃儕鑹筹紝浣嗕笉鍙�惁璁ゅ湪褰撴椂鐨勬妧鏈�潯浠朵笅锛屻�鐙�珛鏃ャ�纭�綋灞炵數褰卞伐涓氬彂灞曚竴閮ㄤ护浜洪渿鎾肩殑閲�..\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"        绮ゅ叕缃戝畨澶�44010402000035鍙�\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"        绮ゅ叕缃戝畨澶�44010402000035鍙�\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>183 lines failed to parse correctly</pre>"
      ],
      "text/plain": [
       "183 lines failed to parse correctly"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file G:\\workspace\\ir\\news.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file G:\\workspace\\ir\\news.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 1493 lines in 0.056052 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 1493 lines in 0.056052 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理 #0 文章完成\n",
      "处理 #1 文章完成\n",
      "处理 #2 文章完成\n",
      "处理 #3 文章完成\n",
      "处理 #4 文章完成\n",
      "处理 #5 文章完成\n",
      "处理 #6 文章完成\n",
      "处理 #7 文章完成\n",
      "处理 #8 文章完成\n",
      "处理 #9 文章完成\n",
      "处理 #19 文章完成\n",
      "处理 #39 文章完成\n",
      "处理 #59 文章完成\n",
      "处理 #99 文章完成\n",
      "处理 #399 文章完成\n",
      "处理 #599 文章完成\n",
      "处理 #999 文章完成\n",
      "处理 #1492 文章完成\n",
      "全部完成！\n"
     ]
    }
   ],
   "source": [
    "weibopath = './weibo.csv'\n",
    "newspath = './news.csv'\n",
    "TF_SELECTOR = True\n",
    "\n",
    "weibos = read_and_cut(weibopath)\n",
    "news = read_and_cut(newspath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始计算微博词向量\n",
      "第 0 条文章原始词向量计算完成\n",
      "第 1 条文章原始词向量计算完成\n",
      "第 2 条文章原始词向量计算完成\n",
      "第 3 条文章原始词向量计算完成\n",
      "第 4 条文章原始词向量计算完成\n",
      "第 5 条文章原始词向量计算完成\n",
      "第 6 条文章原始词向量计算完成\n",
      "第 7 条文章原始词向量计算完成\n",
      "第 8 条文章原始词向量计算完成\n",
      "第 9 条文章原始词向量计算完成\n",
      "第 19 条文章原始词向量计算完成\n",
      "第 39 条文章原始词向量计算完成\n",
      "第 59 条文章原始词向量计算完成\n",
      "第 99 条文章原始词向量计算完成\n",
      "第 399 条文章原始词向量计算完成\n",
      "第 599 条文章原始词向量计算完成\n",
      "第 999 条文章原始词向量计算完成\n",
      "第 2999 条文章原始词向量计算完成\n",
      "第 3999 条文章原始词向量计算完成\n",
      "第 4378 条文章原始词向量计算完成\n",
      "本数据集的原始词向量全部计算完成\n",
      "本数据集的TF-IDF词向量全部计算完成\n",
      "微博词向量全部计算完成\n",
      "\n",
      "开始计算新闻词向量\n",
      "第 0 条文章原始词向量计算完成\n",
      "第 1 条文章原始词向量计算完成\n",
      "第 2 条文章原始词向量计算完成\n",
      "第 3 条文章原始词向量计算完成\n",
      "第 4 条文章原始词向量计算完成\n",
      "第 5 条文章原始词向量计算完成\n",
      "第 6 条文章原始词向量计算完成\n",
      "第 7 条文章原始词向量计算完成\n",
      "第 8 条文章原始词向量计算完成\n",
      "第 9 条文章原始词向量计算完成\n",
      "第 19 条文章原始词向量计算完成\n",
      "第 39 条文章原始词向量计算完成\n",
      "第 59 条文章原始词向量计算完成\n",
      "第 99 条文章原始词向量计算完成\n",
      "第 399 条文章原始词向量计算完成\n",
      "第 599 条文章原始词向量计算完成\n",
      "第 999 条文章原始词向量计算完成\n",
      "第 1492 条文章原始词向量计算完成\n",
      "本数据集的原始词向量全部计算完成\n",
      "本数据集的TF-IDF词向量全部计算完成\n",
      "新闻词向量全部计算完成\n"
     ]
    }
   ],
   "source": [
    "print \"开始计算微博词向量\"\n",
    "weibos_wvec = batch_word_vec_generator(weibos['parsed'] , TF_SELECTOR)\n",
    "print \"微博词向量全部计算完成\"\n",
    "print \"\"\n",
    "print \"开始计算新闻词向量\"\n",
    "news_wvec = batch_word_vec_generator(news['parsed'] , TF_SELECTOR)\n",
    "print \"新闻词向量全部计算完成\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始计算最近邻居\n",
      "第 1 条新闻的最近邻居计算完成\n",
      "第 2 条新闻的最近邻居计算完成\n",
      "第 3 条新闻的最近邻居计算完成\n",
      "第 4 条新闻的最近邻居计算完成\n",
      "第 5 条新闻的最近邻居计算完成\n",
      "第 6 条新闻的最近邻居计算完成\n",
      "第 7 条新闻的最近邻居计算完成\n",
      "第 8 条新闻的最近邻居计算完成\n",
      "第 9 条新闻的最近邻居计算完成\n",
      "第 10 条新闻的最近邻居计算完成\n",
      "最近邻居全部计算完成\n"
     ]
    }
   ],
   "source": [
    "news['word_vec'] = news_wvec['word_vec']\n",
    "news['tf_word_vec'] = news_wvec['tf_word_vec']\n",
    "print \"开始计算最近邻居\"\n",
    "test = news[0:10]\n",
    "\n",
    "test['assign_weibos'] = batch_NN_finder(test['tf_word_vec'] , weibos_wvec['tf_word_vec'] , weibos['id'])\n",
    "print \"最近邻居全部计算完成\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "-------------------------------------------------------\n",
      "分析新闻编号： 1.\n",
      "该新闻内容如下：\n",
      "　　还有两天，2016全国高考就要开始了！　　就在考生们抓紧复习、最后冲刺时，小编也没有闲着，为学子们制作了一份高考备忘录！这里面包括考试时间、天气情况等等……如果你家里有考生，或者身边有考生，就赶快转给他们吧！！　　一旦在去考场的途中遇到堵车，最好的办法就是出示准考证向民警求助。但小编要说的是，防患于未然是避免问题的最好办法，这两天尽可能提前去熟悉考场周围的交通环境，要做到心中有数，以免出现意外。　　路上发现忘带准考证，如果时间宽裕，可向交警求助帮助取回。时间紧的，要主动向监考教师说明情况，尽量协调先进场，及时给家长打电话将准考证送过来。　　如果考前时间宽裕，可在考点附近购买；如果已经开考了，要立即向监考老师报告，切忌相互之间自行传递。　　如果考生眩晕、脸色苍白，可喝点糖水或牛奶，补充能量；或在监考人员的帮助下，选择适当的场所吸氧，或头低脚高仰卧几分钟，以保证大脑足够供血供氧。家长也可给孩子置配一些常用药品，以备孩子偶有不适时调理所需。一般可准备以下物品：保济丸、藿香正气水、风油精等。　　遇到这样的情况，要停止答卷，学会放松。先闭目养神，做深呼吸，默默数数或伏案休息片刻，让大脑做短暂休息，或闭目做深呼吸3～9次，不考虑答卷上的问题；或者把笔放下、向窗外眺望，借此稳定情绪，缓解紧张心理。　　不刻意入睡，让自己处于无意识的状态，能睡则睡，不强迫自己；可以想一些轻松的事情。有了良性的心理暗示后，情绪就会放松，入睡也就容易了。如果情况特别严重，可以在医生指导下适当用药。　　最后小编要为大家送上的锦囊是“平常心”！希望考生能够以平常心对待考试、社会能够以平常心看待高考。如果说人生是场马拉松，那么高考也许只能算是其中一公里的成绩，保持“配速”、沉着应对，才能取得最终的胜利。只要认识到空无的道理，生命就无往而不胜。生命想透了其实与一个晚期癌症病人无异，什么都不必太过执着，喜欢干点什么事就干点什么事而已。“特朗普现象”其实是美国新教文明进入衰退期以后的一次自救。特朗普和他背后的美国群众，是对内外挑战的坚决应战，是美国文明不甘沉沦的生命活力迸发。而与之对立的建制派，则是腐朽的、堕落的。特朗普参选的结果，将决定美国未来是走向中兴还是就此沉沦。中国的科技教育体制需要进一步完善，对这一点大家有广泛共识。完善体制的重要举措之一就是支持年轻人，特别是那些独立生涯起步不久、相当于国外助理教授时期的年轻科学工作者，以及当代科学研究的主力军：博士后和研究生。从上个世纪80年代以来有越来越多国家的共产党与社会党开始不同程度的互相交往、联合斗争。中共自1982年以来也与社会党国际和多国社会党建立联系，甚至多次派代表以观察员身份参加社会党国际每隔三年召开一次的国际代表大会。Copyright ©1996-2016 SINA Corporation, All Rights Reserved\n",
      "\n",
      "总共匹配文章数： 10.\n",
      "以下是匹配列表：\n",
      "-------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3982762123284430.\n",
      "['【还有两天了！请收藏这份高考备忘录！】还有两天，2016全国高考就要开始。就在考生们抓紧复习、最后冲刺时，媒体专门为高考学子们制作了一份高考备忘录，包括考试时间、天气情况等等……如果你家里有考生，或者身边有考生，就赶快转给他们吧！http://t.cn/R5qYnPL @央视新闻', ... ]\n",
      "计算所得距离系数： 82.134850.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3983860234057467.\n",
      "['\"致高考生', ... ]\n",
      "计算所得距离系数： 84.127875.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3983693754451453.\n",
      "['#2016高考#【2016年广东高考语文作文题目来了↓↓】如果你是考生，准备怎么写？（羊城晚报高考直播团队）', ... ]\n",
      "计算所得距离系数： 84.396012.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3983692873581668.\n",
      "['#2016高考#【全国卷高考语文作文题目来了↓↓】如果你是考生，准备怎么写？（羊城晚报高考直播团队）', ... ]\n",
      "计算所得距离系数： 84.399487.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3983855385883047.\n",
      "['世界很暖，因为有你们[心]', ... ]\n",
      "计算所得距离系数： 84.577895.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3983657368830276.\n",
      "['#广州高考进行时#开考了！（羊晚记者陈晓璇摄）', ... ]\n",
      "计算所得距离系数： 84.616202.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3983045046891781.\n",
      "['#下午茶#中国好同桌。。。。。', ... ]\n",
      "计算所得距离系数： 84.676524.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3983460282254153.\n",
      "['#2016高考#对于即将到来的考试，周刊君想说的简单直接，戳图，祝各位考生好运！#高考加油#', ... ]\n",
      "计算所得距离系数： 84.721606.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3990718667752140.\n",
      "['#2016高考季#【[推荐]一张图告诉你全国31个省市区高考分数线】戳图↓转给考生！还记得你当年的高考成绩吗？', ... ]\n",
      "计算所得距离系数： 84.748120.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3986933799546145.\n",
      "['上海迪士尼，今天中午12点，正式开园。', ... ]\n",
      "计算所得距离系数： 84.878952.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "-------------------------------------------------------\n",
      "分析新闻编号： 5.\n",
      "该新闻内容如下：\n",
      "从昨天（3日）开始，在上海，有一群人冒着雨，在上海影院门口等待着什么，就像这样：到了今早（4日）7：30分左右，这支队伍变得更长了：原来，第19届上海国际电影节于今天上午8时正式开票，他们都是前来买票的观众。排在队伍最前的是孙小姐，她从昨天下午2点就开始等待，她告诉东方网记者：今年最想看的是日本影片：《和母亲一起生活》、《暗杀教室》等，为了这些难得一见的电影，排18个小时的队也是值得的。还有一位70岁高龄的“铁杆影迷”方先生，他从第一届上海电影节开始每年都会第一时间来现场买票。今天，方先生赶乘地铁首班车早早到达现场，他告诉东方网记者：自己这几天一直都在作“功课”，列出了一份长长的电影节心愿片单，今年最想看的是好莱坞影片《乔布斯》。在网络上，另一群人也是早早定好8：00分的闹钟，打算通过淘票票APP来订票。每经小编（微信号：nbdnews）了解到，6月11日到19日，第19届上海国际电影节将举行。日前公布了此次展映的完整片单及排片表，这次参加展映的影片有近600部。不仅有在大银幕上极为罕见的大师之作、今年戛纳电影节的入围电影，还有年轻人喜欢的日韩片，《哈利·波特》系列八部连映、莎翁影展、迪斯尼·皮克斯电影周、007回顾等，被影迷称为“上影节史上最强片单”。其中，电影节推出的“安德烈·塔可夫斯基回顾展”非常重磅，《伊万的童年》等多部名作都将在电影节公映。这些片子在上海的放映场次将超过1250场。这是部分将会在电影节期间放映的影片海报：此时的上海影城，已经接近9点，百米长队迟迟得不到动弹。▲聚集在现场的影迷一边等待，一边用手机刷票（图片来源：东方网）原来，影院和淘票票APP采用的是同一个售票系统后台，因此大批聚集在影院现场的影迷依然无法购票。另据中国青年网消息：铁杆影迷徐先生表示，他就是因为担心购票网站“秒杀”和网络崩溃问题，才想着自己现场来买踏实些，可以根据购票情况随时做出调整。“没想到今年系统崩溃，一直等到现在都没买到。”心疼70岁高龄的方先生，遇到了19年一次的“系统崩溃”……▲排在最前面的两个姑娘，买到了心仪的电影票。图片来源：新民晚报到了9：12分，第一位排队的影迷孙小姐才拿到了她的第一张票，她已经排了19个小时的队。在10：30分，情况有所好转，网站终于开始运行，但当网络购票的观众看到座位表的时候，差点吐血：中央的位置已经全被售空，只剩一些角落和前排。每经小编（微信号：nbdnews）也跟大家一样，开始了艰难的“刷票”之旅……为什么一票如此难求？在10:42分，@上海国际电影节 给出的解释是：电影节今天早晨8点开票后，由于淘票票系统流量过大，导致一时无法出票。在11:25分，@淘票票也发布了一封致歉信。另据此前《新民晚报》报道，上影节组委会不仅提到流量比前几年增加十几倍的客观原因，还指出淘票票服务器可能遭遇黑客攻击，目前已经报警，准备彻查此事。在上午11：30分，每经小编（微信号：nbdnews）联系到了本届上海电影节负责选片和展映的主管鞠里求证上述情况。鞠里表示：目前还无法给出一个确切的官方信息，但组委会已经力所能及解决今晨发生的票务问题。那么现在，大家买到自己心仪的电影票了吗？这次，每经小编（微信号：nbdnews）买到了今年大热的4k影片《地下》和《豹》。我要去发朋友圈炫耀了，大家下周电影院见。|  本文转自每日经济新闻 nbdnews |微信推出了新功能你知道吗？升级到最新版后，可以选择微信公众号置顶了。欢迎把每经小编置顶，第一时间接收内容推送，麻麻再也不用担心我抢不到沙发了。\n",
      "\n",
      "总共匹配文章数： 10.\n",
      "以下是匹配列表：\n",
      "-------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3982771523437877.\n",
      "['【今早好多人定闹钟准备抢TA！还有人通宵排队19个小时！结果......】从昨天（3日）开始到今晨，在上海，有一群人冒着雨，在上海影院门口等待着什么。原来，第19届上海国际电影节于今天上午8时正式开票。在网络上，另一群人也是早早定好8：00分的闹钟，打算通过淘票票APP来订票。http://t.cn/R5qmLUH', ... ]\n",
      "计算所得距离系数： 129.637874.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3985335827986880.\n",
      "['【[推荐]第19届上海国际电影节开幕！】第19届上海国际电影节11日开幕，成龙、刘烨、黄晓明夫妇、杨洋、舒淇、宋茜、李敏镐等300多位中外艺人出席红毯仪式。在电影节主竞赛单元金爵奖评选中，共有2403部影片角逐个奖项。电影节上还将展映近600部中外佳片。你最期待那部影片？谁的表现？（央视记者曹岩）', ... ]\n",
      "计算所得距离系数： 133.300552.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3985340899025820.\n",
      "['【[推荐]第19届上海国际电影节开幕！】第19届上海国际电影节11日开幕，成龙、刘烨、黄晓明夫妇、杨洋、舒淇、宋茜、李敏镐等300多位中外艺人出席红毯仪式。来自114个国家和地区的2403部影片报名参节。电影节上还将展映近600部中外佳片。你最期待那部影片？谁的表现？转发说说吧！（央视记者曹岩）', ... ]\n",
      "计算所得距离系数： 134.106814.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3985551561990381.\n",
      "['【第19届上海电影节开幕 女神范冰冰、刘亦菲、舒淇红毯秀（组图）】6月11日，第19届上海国际电影节开幕，女神们在红毯上上演华服秀。http://t.cn/R5Ji4ST', ... ]\n",
      "计算所得距离系数： 135.338805.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3986933799546145.\n",
      "['上海迪士尼，今天中午12点，正式开园。', ... ]\n",
      "计算所得距离系数： 138.524949.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3983855385883047.\n",
      "['世界很暖，因为有你们[心]', ... ]\n",
      "计算所得距离系数： 138.712332.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3983045046891781.\n",
      "['#下午茶#中国好同桌。。。。。', ... ]\n",
      "计算所得距离系数： 138.772491.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3983860234057467.\n",
      "['\"致高考生', ... ]\n",
      "计算所得距离系数： 138.785046.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3990028566966882.\n",
      "['原来女生多少和招生有这么大的关系？[doge]你觉得呢？[偷笑]', ... ]\n",
      "计算所得距离系数： 138.916627.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3989914469104827.\n",
      "['快讯：英国首相卡梅伦宣布辞职。', ... ]\n",
      "计算所得距离系数： 138.943183.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "-------------------------------------------------------\n",
      "分析新闻编号： 6.\n",
      "该新闻内容如下：\n",
      "　　新华社无锡6月4日体育专电(记者 王镜宇 王恒志)国家体育总局棋牌运动管理中心党委书记、国际围棋联盟事务总长杨俊安4日在这里透露，如果不出意外柯洁九段将在年内进行和“阿尔法狗”的围棋“终极人机大战”。　　在4日下午举行的第37届世界业余围棋锦标赛新闻发布会上，杨俊安透露了这一消息。据他介绍，中国围棋协会和“阿尔法狗”的团队就此事进行了接触和沟通，双方都有意向促成这项对抗。如果不出意外的话，这次比赛将安排在年内，但是具体时间和比赛地点等还“无从谈起”。　　今年3月进行的“阿尔法狗”和李世石的围棋人机大战引起了全世界的广泛关注。来自中国、韩国、欧洲和美国的围棋官员均表示，这次对抗极大提升了围棋在当地的关注度。在此间举行的国际围棋联盟全体代表大会上，还有人提议向“阿尔法狗”颁发“围棋推广特别贡献奖“。　　在那场举世瞩目的人机大战中，“阿尔法狗”以4：1战胜了韩国名将李世石九段。不过，中国等级分排名第一的柯洁九段当时就表示，虽然“阿尔法狗”战胜了李世石，但它赢不了自己。因此，有不少棋迷也期待看到柯洁和“阿尔法狗”的对决。　　据刚刚卸任的国际围棋联盟事务局长、韩国棋手李夏辰介绍，李世石和“阿尔法狗”的人机大战为围棋在韩国所赢得的关注是空前的。当时，包括KBS等重量级电视台在内的9家电视媒体对比赛进行了转播，收视率接近男足世界杯，李世石也成为国家英雄一样的人物。(完)\n",
      "\n",
      "总共匹配文章数： 10.\n",
      "以下是匹配列表：\n",
      "-------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3983279083827168.\n",
      "['【柯洁年内将战“阿尔法狗”，你看好谁？】据新华社，国际围棋联盟事务总长杨俊安昨天透露，如果不出意外柯洁九段将在年内进行和“阿尔法狗”的围棋“终极人机大战”。今年3月，“阿尔法狗”以4：1战胜韩国名将李世石，但柯洁当时就表示，“阿尔法狗”赢不了自己。你看好谁？投票↓网页链接人民日报', ... ]\n",
      "计算所得距离系数： 75.998972.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3982770327468562.\n",
      "['#热点#【柯洁年内将战“阿尔法狗” 你看好谁赢？】国家体育总局棋牌中心党委书记杨俊安今天透露，如果不出意外，柯洁九段将在年内与“阿尔法狗”进行围棋“终极人机大战”，但是具体时间和地点待定。今年3月，在与李世石的5局围棋人机大战中，“阿尔法狗”以4：1获胜。http://t.cn/R5q8rUC', ... ]\n",
      "计算所得距离系数： 79.833287.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3983133378555945.\n",
      "['【[威武]#柯洁年内将战AlphaGo#  你看好谁赢？】4日，国家体育总局棋牌运动管理中心党委书记杨俊安透露，如不出意外@棋士柯洁 九段将在年内进行和“阿尔法狗”的围棋“终极人机大战”，具体时间和地点待定。今年3月，在与李世石的5局围棋人机大战中，“阿尔法狗”以4：1获胜。http://t.cn/R55ouDt(环球网)', ... ]\n",
      "计算所得距离系数： 84.679433.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3983702906615144.\n",
      "['【阿尔法狗之父否认中国版人机大战：暂无比赛计划】近日有消息称，中国柯洁九段将在年内和“阿尔法狗”围棋进行“终极人机大战”。对此，“阿尔法狗之父”哈萨比斯于6日在社交平台表示，这些不过都是网上的传言，“阿尔法狗”暂时没有比赛计划，一旦有的话，会有官方的通知。http://t.cn/R5c8kGP', ... ]\n",
      "计算所得距离系数： 90.370041.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3982771774454337.\n",
      "['【#柯洁年内将战AlphaGo# 你看好谁赢？】国家体育总局棋牌中心党委书记杨俊安今天透露，如果不出意外，柯洁九段将在年内与“阿尔法狗”进行围棋“终极人机大战”，但是具体时间和地点待定。详细：http://t.cn/R5qm5sk', ... ]\n",
      "计算所得距离系数： 95.040061.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3983135643413692.\n",
      "['某推主前几天去宠物店，看到橱窗里有只狗在...极力推销自己[doge] http://t.cn/R5GOfVt', ... ]\n",
      "计算所得距离系数： 107.930420.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3983032837269587.\n",
      "['某推主前几天去宠物店，看到橱窗里有只狗在...极力推销自己[doge] http://t.cn/R5GOfVt', ... ]\n",
      "计算所得距离系数： 107.930420.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3983855385883047.\n",
      "['世界很暖，因为有你们[心]', ... ]\n",
      "计算所得距离系数： 108.132231.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3983045046891781.\n",
      "['#下午茶#中国好同桌。。。。。', ... ]\n",
      "计算所得距离系数： 108.248185.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3983860234057467.\n",
      "['\"致高考生', ... ]\n",
      "计算所得距离系数： 108.287026.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "-------------------------------------------------------\n",
      "分析新闻编号： 9.\n",
      "该新闻内容如下：\n",
      "            在郑州经营近3年的方大同胡辣汤店在郑州有一定知名度，有着两家直营店和12家连锁店。去年5月，“方大同胡辣汤餐饮连锁店”的老板康长喜突然收到香港知名歌手方大同委托律师发来的函，说他的商标对方大同本人构成了姓名权侵害。今年4月18日，经国家工商行政管理总局商标评审委员会裁定，该商标属于无效商标。          原标题：郑州方大同胡辣汤商标被裁定无效 店老板决定起诉 我方大同出名之后，你的方大同胡辣汤店才开的。方大同，1983年出生，2005年出道，2011年登上央视春晚。我没有高攀明星的意图。我的邻居家有个大哥叫大同，每次叫他的时候，都有一种亲近感。给早餐店起名时，我就想到了这个名字。朋友说，叫大同挺好，叫起来不仅清脆响亮，此外大同也是一个地名，叫方大同与方中山差不多。与知名歌手方大同“撞名”郑州“方大同胡辣汤”商标被裁定无效店老板决定起诉保卫“品牌”在郑州经营近3年的方大同胡辣汤店在郑州有一定知名度。然而，这家胡辣汤连锁企业因为和明星“撞名”，正在遭遇一场危机。去年5月，“方大同胡辣汤餐饮连锁店”的老板康长喜突然收到香港知名歌手方大同委托律师发来的函，说他的商标对方大同本人构成了姓名权侵害。今年4月18日，经国家工商行政管理总局商标评审委员会裁定，该商标属于无效商标。眼见“方大同”的名号越来越响，康长喜对这一裁定结果难以接受，说自己当初在注册商标时，根本不知道有个叫同样名字的歌手。他决定通过法律手段来保住“方大同”的名号。5月31日上午11时，记者一路打听，在郑州市秦岭路与电厂路交叉口北侧的华强广场上，找到了正在店里忙活的康长喜。已过早餐时间，但店里顾客仍不少。该店门头上，写着“方大同胡辣汤郑州旗舰店”。康长喜说，这是他在郑州的第二家直营店，刚开业半年，投资167万元，专营胡辣汤等早餐。之前，他已经开了一家直营店和12家连锁店。提起“方大同胡辣汤”商标被注销一事，37岁的康长喜一脸愁容。他告诉大河报记者，他从小生长在周口商水县胡吉镇北康村三组。初中毕业后，因家里经济条件不好，便独自跑到北京打工。当过装修工、开过装饰公司，后来，发现郑州早餐卖胡辣汤的店比较火，尤其是带“方”字头的店，生意一家比一家好，比如方中山、方团结、方秀华等。“我当时觉得，如果也开一家带‘方’字头的胡辣汤店，既能借势，又图个吉利，生意一定会火。”康长喜说，当时打定主意后，他就叫了几个朋友，一起商议着起店名。第一个字“方”定下了，后面的两个字叫啥呢？朋友说，人家方中山后面的两个字是地名，咱不妨也找个地名，还得叫着响亮。“邻居家有个大哥叫大同，每次叫他的时候，都有一种亲近感。给早餐店起名时，我就想到了这个名字。朋友说，叫大同挺好，叫起来不仅清脆响亮，此外大同也是一个地名，叫方大同与方中山差不多。”康长喜对自己的店名很是自豪，当然，这个店名也给他带来了好运。他的第一家胡辣汤店，于2012年7月4日正式开业，并在中原区工商局进行了注册。在接下来的3年多时间里，他又一连开了12家连锁店和一家直营店。“去年4月的一个傍晚，我正在市场上忙着采购，远在周口老家的弟弟打来电话，说有人给我寄了一封邮件。”康长喜说，他觉得不可思议，离开家乡到外面已经打拼了20年，任何熟悉他的人，都不会把给他的邮件寄到老家去。“弟弟说是律师发过来的，好像是我惹了什么官司。弟弟怕耽误我的事，连夜把邮件送到了郑州。我看完邮件的内容后，头一下就蒙了！”康长喜说，他以前只是关心如何打拼挣钱，从未关注过娱乐圈的事，即使当红的歌星、影星，他也很少能叫出名字。他做梦也想不到，自己胡辣汤店的注册商标，竟会与一名歌手相同，以至于被对方委托律师发函，要求他立即停止侵害姓名权的行为。康长喜认为，他目前已经拥有14家门店，其中12家为加盟店，如果更换商标，会对加盟商产生信任危机，已签署的合同将存在违约风险。对于顾客，一旦店名更换，尽管还是同样的厨师同样的味道，顾客仍会产生怀疑，认为餐厅已经易主，味道已不是从前的味道，会出现短期客流量下滑。4月18日，国家工商行政管理总局商标评审委员会（以下简称评审委员会）下发了《关于第13096619号“方大同胡辣汤”商标无效宣告请求裁定书》。5月31日上午，记者试图通过微博私信联系歌手方大同，但未得到回信。当天下午，记者又联系了他在广州和上海的代理经纪公司，对方工作人员均称不了解情况。裁定书称，早在去年4月3日，歌手方大同便委托鸿鹄知识产权代理（北京）有限公司，向评审委员会提出申请，请求宣告第13096619号“方大同胡辣汤”商标（以下称争议商标）无效。对方申请的理由是，“方大同”系申请人中文姓名，已在中国及华语地区取得较高知名度，争议商标构成对申请人姓名权的侵害。此外，争议商标具有欺骗性，易使公众对服务特点或来源产生误认，且混淆和误认已实际发生。被申请人在其经营的餐厅店招（商店招牌）上突出使用“方大同”三个字，相关公众易认为该店是由申请人经营或许可经营，给公众造成误导，被申请人具有攀附申请人知名度的恶意。为了证明“方大同胡辣汤”侵害姓名权，申请人还向评审委员会提交了13组证据，其中包括申请人多年来所获得的荣誉，所参加的演出、相关的新闻报道以及被申请人经营的早餐店工商登记信息等，认为康长喜开的胡辣汤店，是在其出名后才开的。为了证明自己没有高攀明星的意图，康长喜向评审委员会提交了自己的个体工商户名称预先核准通知书，所经营的“郑州市中原区方大同胡辣汤总店”个体工商户营业执照副本复印件，河南省内以“方”字冠名的胡辣汤店查询信息等证据。被裁定损害他人的在先权利，郑州“方大同”不服裁定决定起诉评审委员会经审理后认为，在案证据足以证明争议商标申请日前，申请人方大同已经具有一定社会知名度，早于被申请人主张的其含有“方大同”的企业名称的登记日期2012年6月前亦具有一定知名度。此外，申请人曾于争议商标申请日前，在郑州参加了2013民安北郡揽群星大型惠民关爱演唱会，被申请人对申请人姓名及知名度理应知晓。争议商标“方大同胡辣汤”完整包含了申请人姓名，被申请人未经申请人授权、将与申请人中文姓名相同的文字申请注册商标，虽然指定使用的餐厅、茶馆等服务与申请人方大同所知名的娱乐行业无直接关系，但其注册客观上利用了申请人的较高知名度，亦可能误导公众，认为申请人与其存在某种商业联系，从而对申请人的姓名可能造成损害，因此，争议商标已构成《商标法》第三十二条所指的损害他人现有的在先权利（姓名权）之情形。依据《商标法》第三十二条、第四十五条第一款、第二款和第四十六条的规定，该委裁定如下：争议商标予以无效宣告。裁定书上显示，当事人如不服本裁定，可在规定的时间内，向北京知识产权法院起诉。康长喜说，他不会坐以待毙，即使有万分之一的希望，他也会尽力保住自己的店名和注册商标。下一步，他将通过北京一家律师事务所的律师，向北京知识产权法院起诉。上海现全国第一天价豪宅 成交单价超过34万元土耳其半年遭遇5次恐怖袭击，景点免费开放仍无人问津明知宋仲基是韩国定制的明星 为什么你还要追？大陆地产大亨都开什么车？王石的车最便宜！泰国女神首登熊猫TV 观众看傻：画风有毒（组图）        Copyright © 2016 每日经济新闻报社版权所有，未经许可不得转载使用，违者必究。              广告热线  北京: 010-58528290， 上海: 021-61283008， 广州: 020-84201861， 深圳: 0755-83520159， 成都: 028-86612828      \n",
      "\n",
      "总共匹配文章数： 0.\n",
      "以下是匹配列表：\n",
      "-------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "-------------------------------------------------------\n",
      "分析新闻编号： 10.\n",
      "该新闻内容如下：\n",
      "　　今天要说的这个故事，也许只有在电视剧里才会看到。今天，我找到了一对小夫妻，听他们说这段奇妙的缘分。　　5月29日，是新娘陆怡沁和新郎张何栋大喜的日子。在婚礼前一周的那个晚上，小两口正在家里整理儿时的照片，准备在婚礼那天投放到现场的大屏幕。　　当张何栋把16年前一张在景区拍的照片，扫描进电脑并放大的时候，一旁站着的陆怡沁大叫一声，还跳了起来：“老公，你背后的那个人，不是我妈妈吗？”　　这对新人是嘉兴人，新娘25岁，新郎30岁，都住在南湖区，两家其实离得很近，不过，在2015年3月份经朋友介绍下，男生女生才第一次认识。　　“第一次见到他，对他的印象有点呆呆的，但感觉人蛮好，很亲切，很自然，像是一家人感觉，就觉得可能要嫁的就是这个男人了。” 陆怡沁说，相熟后，两人相处的很不错，半年过去，就到了谈婚论嫁的阶段。　　陆怡沁本以为只是一场普通得不能再普通的恋情，相亲、相识、相熟、相知、相爱，约会、吃饭、逛街、看电影，谈得差不多了，两家人开始催着说，可以结婚了。　　“你让我现在回想当初谈恋爱的细节，我可能都不太记得，反正就是跟大多数的恋爱一样，很平静的爱着，经过一年多的相处，感觉互相之间的爱越来越深，然后就想着可以组个家庭了。”今年春节后，两人认真商量了一下结婚的事情，最终定下来，今年5月29日办婚礼。　　婚礼上，总要想一些浪漫，而且能感动客人的环节。夫妻俩想了很久，打算把两人从小到大的照片，尽可能多地找出来，在婚礼上还原彼此的童年和青春。　　婚礼前一个星期，当年的胶片照片找出来很多，张何栋开始一张张扫描进去，打算做一本电子画册，可以在婚礼现场播给客人看。　　扫描一张，两人就回忆一次当年的经历。　　“你看，这是我14岁的时候，那年是2000年，一家人赶流行，说是千禧年来了，去无锡灵山大佛祈福。你看我当年长的也挺帅吧。” 张何栋把这张有些泛黄的照片扫进电脑后，一边放大一边跟陆怡沁说。　　陆怡沁没看16年前的老公，倒是照片中，一个穿红衣服的女人让她凑近去看。　　这张照片里的红衣女子，就是张何栋的丈母娘。　　“再放大一看，我就大声叫了起来，我的妈呀！老公还说干嘛这么大惊小怪，我说，这真的是我妈妈呀。” 陆怡沁说，当时自己还蹦了起来，说妈妈怎么会出现在照片里？　　因为要收拾新房子，陆怡沁的妈妈当时也在新家，她就叫妈妈一起来看。　　妈妈觉得不可思议，一直说：“这怎么可能啊，哪有这么巧的事情。”　　可是，再看看，妈妈说这个人真的是自己，而且那年一家人也确实去过同一个景区，家里也留着这张照片。　　陆怡沁的妈妈回忆了一下日子，虽然不记得是几月几日，但确定是当年的大年初五。　　陆怡沁回到娘家，翻出来了那天拍的照片，同样的衣服，同样的地方，什么都对上了。　　而更巧的是，两家除了都留着照片，连当天入景区的门票也都一直珍藏着。　　张何栋说，也不知道为什么，他的爸爸一直把门票放在钱包里，16年来，钱包换了好几个，门票却一直都在。　　“原来我这16年，等的就是你呀。”被这两张照片有些搞懵了的张何栋，一把抱住了陆怡沁。　　“超级不可思议啊，要不是有照片为证，我都以为这是编故事。现在我特相信缘分了，冥冥中就注定了。”陆怡沁马上给婚礼的司仪打电话，说一定要把这个故事，讲给当晚的每一位客人听。　　那天晚上，陆怡沁通过电子邮件，把照片发给了司仪。　　婚礼那天，司仪讲完照片的故事，完成所有流程后，偷偷跑过来为这对新人：“你们这照片不是PS的吧，我做了9年婚礼司仪了，还是第一次碰到。”　　不光司仪不信，当晚听到这个故事的所有客人也觉得好神奇。婚礼结束后，陆怡沁的微信里收到了好多朋友发来求证的信息，都是来问照片是真是假。　　那天的婚礼，主题是亲情。“老公说，虽然那时候彼此都不认识，但老天一定是已经给我们安排了16年后的事情，所以其实亲情早已经等着我们了，有了这样妙不可言的缘分，以后会更加珍惜这份感情。”　　婚礼忙完了，夫妻俩也已经订好了6月7日去欧洲旅行的机票。　　“我们打算去法国、瑞士，这两个都是浪漫的国家，我一直以为自己和老公都不是浪漫的人，但估计照片会改变我们的想法的。”陆怡沁说，这次出去旅 游，他们还要在飞机上，在旅途中，边走边说各自的往事，“说不定在某一年嘉兴的街头，我们也曾出现在同一个场合，说不定我们还会有更多不可思议的交集 呢。”　　陆怡沁在跟我讲这个故事的时候，我能听出来，她的声音是激动的，还有一些兴奋。　　在采访结束的时候，我跟陆怡沁说，等报纸出来了，我会给她寄一份过去，她把这么美好的故事分享给快报，我就把报纸当一份礼物祝他们新婚快乐。　　“真的吗？那这份礼物就太珍贵了，我一定会好好保存起来，以后讲给我们的孩子听。” 陆怡沁说。只要认识到空无的道理，生命就无往而不胜。生命想透了其实与一个晚期癌症病人无异，什么都不必太过执着，喜欢干点什么事就干点什么事而已。“特朗普现象”其实是美国新教文明进入衰退期以后的一次自救。特朗普和他背后的美国群众，是对内外挑战的坚决应战，是美国文明不甘沉沦的生命活力迸发。而与之对立的建制派，则是腐朽的、堕落的。特朗普参选的结果，将决定美国未来是走向中兴还是就此沉沦。中国的科技教育体制需要进一步完善，对这一点大家有广泛共识。完善体制的重要举措之一就是支持年轻人，特别是那些独立生涯起步不久、相当于国外助理教授时期的年轻科学工作者，以及当代科学研究的主力军：博士后和研究生。从上个世纪80年代以来有越来越多国家的共产党与社会党开始不同程度的互相交往、联合斗争。中共自1982年以来也与社会党国际和多国社会党建立联系，甚至多次派代表以观察员身份参加社会党国际每隔三年召开一次的国际代表大会。Copyright ©1996-2016 SINA Corporation, All Rights Reserved\n",
      "\n",
      "总共匹配文章数： 0.\n",
      "以下是匹配列表：\n",
      "-------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "-------------------------------------------------------\n",
      "分析新闻编号： 12.\n",
      "该新闻内容如下：\n",
      "6月3日，路透社报道称，有据知情人士表示，捷豹路虎正起诉中国江铃汽车公司，指控该公司的SUV陆风X7涉嫌抄袭路虎揽胜极光（Range Rover Evoque）的车型设计。捷豹路虎的一位发言人在给路透的一份邮件评论中表示，该公司“已就专利和不公平竞争问题”向北京市朝阳区一家法院提起诉讼。2014年11月，江铃旗下的陆风汽车公司于推出了X7车型，售价只有揽胜极光在中国售价的大约三分之一。这款X7车型与揽胜极光到底像不像，来看一组对比图：▲左为陆风，右为路虎（图片来源：网易汽车）网易汽车联系到陆风汽车营销公司副总经理潘欣欣对此表示，“我们也是在网上看到这个消息，至于如何应对，只有八个字——兵来将挡，成竹在胸。”实际上，由于两车外观相似，2014年X7推出不久后就被外媒指责抄袭。德国《商报》就曾以“源自山寨工厂的中国极光”的标题报道了此事，该文章称虽然陆风X7比路虎极光长了10cm，但从前脸、挡泥板到车顶都几乎跟极光一致。在内饰方面，也几乎照搬极光的驾驶舱，唯一的区别是触摸屏更大一点，还有就是江铃汽车的标志取代了路虎的标志。路透的报道则称，两辆车之间的细微差异还可以使用相关配件来消除，例如揽胜极光的前格栅、标志都可以在淘宝网上买到，价格只要128元。路透还声称，尽管中国汽车行业存在广泛和经常的抄袭行为，但外国汽车厂商针对中国企业采取法律行动的做法仍然十分罕见。而此次就捷豹路虎和江铃陆风的争议，每经小编（微信号：nbdnews）查询国家知识产权局相关中国专利发现，陆风与捷豹路虎方面均在外观方面注册了知识产权。陆风X7研发代号是E32，专利号：2013305282265，在2013年11月申请外观专利。而捷豹路虎方面，专利号为：2011304364593，申请日期为2011年11月24日。实际上，陆风与路虎结仇已久。早在2006年，陆风汽车进军欧盟时，路虎就以陆风汽车注册的“LANDWIND”英文商标与其“LAND ROVER”太像，而将陆风汽车告上欧盟内部市场协调局。在经历了长达六年的，判定商标侵权——上诉——维权成功一系列事件之后，陆风汽车才成功拿到了“LANDWIND”在欧盟的注册商标。其实，关于抄袭引发的纠纷，在汽车行业并不鲜见，而且外国车企起诉国内车企抄袭，也已经不是个案，比较有名的案例是，2004年本田汽车起诉双环，指控后者推出的来宝SRV抄袭了本田的CRV。这一官司历时12年，法院最终判决本田的诉求不成立，驳回了其高达3.5亿元的索赔请求。但令不少人以外的是最终出现的反转，本田的诉求不但不成立，最后还要赔偿双环汽车人民币1600万元。这是由于双环反诉了本田，认为其产品来宝S-RV销量不佳和提前停产应归咎于本田，本田对中国竞品进行打压封杀以求独大，牟取不正当竞争利润。对此，双环提出诉求，要求法院否认己方侵权，并判处本田侵犯了双环的合法经营权和名誉权，索赔人民币36574万元，并承担相应的诉讼费用。法院最终判定本田赔偿人民币1600万元。对于此次捷豹路虎在国内起诉陆风，有专家表示，这可能也是一场持久战。|  本文转自每日经济新闻 nbdnews |微信推出了新功能你知道吗？升级到最新版后，可以选择微信公众号置顶了。欢迎把每经小编置顶，第一时间接收内容推送，麻麻再也不用担心我抢不到沙发了。\n",
      "\n",
      "总共匹配文章数： 10.\n",
      "以下是匹配列表：\n",
      "-------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3982784882238474.\n",
      "['【都是“Lu”家人，路虎却把陆风告上了法庭……】6月3日，路透社报道称，有据知情人士表示，捷豹路虎正起诉中国江铃汽车公司，指控该公司的SUV陆风X7涉嫌抄袭路虎揽胜极光（Range Rover Evoque）的车型设计。对于此次路虎在国内起诉陆风，有专家表示可能是一场持久战。你怎么看？http://t.cn/R5qBYJH', ... ]\n",
      "计算所得距离系数： 169.587943.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3983807571111738.\n",
      "['#思考#佛口蛇心------泰国警方在著名的虎庙进行了搜查，揭开了这个传说中僧人与虎和谐相处的寺庙背后的黑暗故事。@英国报姐', ... ]\n",
      "计算所得距离系数： 194.869065.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3990368300997746.\n",
      "['【英国脱欧，两条腿的都懵了，四个轮儿的都哭了】英国脱欧的影响之一就是，英国与欧盟以及其他市场需要确定新的免税协议，在这个过程中，“关税”或将成为一个不小的麻烦。许多跨国车企、特别是在英国有大量投资企业现已“哭晕在厕所”。其中最受伤的，或许正是捷豹路虎。http://t.cn/R5jvP6e', ... ]\n",
      "计算所得距离系数： 195.423632.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3986673957851612.\n",
      "['如果汽车全部实现无人驾驶，开车时会不会很无聊？让这两个外国歪果仁教你怎么玩。http://t.cn/R5XoILk', ... ]\n",
      "计算所得距离系数： 196.437172.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3983045046891781.\n",
      "['#下午茶#中国好同桌。。。。。', ... ]\n",
      "计算所得距离系数： 196.517424.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3983855385883047.\n",
      "['世界很暖，因为有你们[心]', ... ]\n",
      "计算所得距离系数： 196.537613.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3983860234057467.\n",
      "['\"致高考生', ... ]\n",
      "计算所得距离系数： 196.588940.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3986933799546145.\n",
      "['上海迪士尼，今天中午12点，正式开园。', ... ]\n",
      "计算所得距离系数： 196.666491.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3990028566966882.\n",
      "['原来女生多少和招生有这么大的关系？[doge]你觉得呢？[偷笑]', ... ]\n",
      "计算所得距离系数： 196.681854.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3991478113617174.\n",
      "['【晚安心语】没人扶你的时候，自己要站直，路还长，背影要美。', ... ]\n",
      "计算所得距离系数： 196.683181.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "-------------------------------------------------------\n",
      "分析新闻编号： 14.\n",
      "该新闻内容如下：\n",
      "　　坐飞机的时候，会不会总是担心飞机的安全性？最近乌克兰的一位工程师提出了一项新专利，可以彻底打消你的疑虑！　　这项专利设计的飞机客舱和驾驶舱是分离的。在出现紧急事故时候，可以将客舱和机身分离，机身上方会有降落伞、机身下方会有充气垫防护。　　甚至连行李都不会受到损失，因为行李位于客舱甲板下方。 Copyright © 1996-2016 SINA Corporation, All Rights Reserved \n",
      "\n",
      "总共匹配文章数： 10.\n",
      "以下是匹配列表：\n",
      "-------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3982792544493101.\n",
      "['#未来世界#【再也不怕空难了！这项新专利有点神奇】坐飞机的时候，总是担心飞机的安全性？乌克兰的一位工程师提出了一项新专利：飞机客舱和驾驶舱是分离的。在出现紧急事故时候，可以将客舱和机身分离，机身上方会有降落伞、机身下方会有充气垫防护。http://t.cn/R5G1vcr 可是，驾驶员怎么办[疑问]', ... ]\n",
      "计算所得距离系数： 27.341856.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3983855385883047.\n",
      "['世界很暖，因为有你们[心]', ... ]\n",
      "计算所得距离系数： 41.052273.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3983860234057467.\n",
      "['\"致高考生', ... ]\n",
      "计算所得距离系数： 41.297302.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3983045046891781.\n",
      "['#下午茶#中国好同桌。。。。。', ... ]\n",
      "计算所得距离系数： 41.314746.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3990028566966882.\n",
      "['原来女生多少和招生有这么大的关系？[doge]你觉得呢？[偷笑]', ... ]\n",
      "计算所得距离系数： 41.737362.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3986933799546145.\n",
      "['上海迪士尼，今天中午12点，正式开园。', ... ]\n",
      "计算所得距离系数： 41.797179.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3989914469104827.\n",
      "['快讯：英国首相卡梅伦宣布辞职。', ... ]\n",
      "计算所得距离系数： 41.825666.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3983795743163258.\n",
      "['如果能回到高中，你最想对自己说什么_______', ... ]\n",
      "计算所得距离系数： 41.830507.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3990879162602118.\n",
      "['【15个习惯，让你每天遇见更好的自己】', ... ]\n",
      "计算所得距离系数： 41.830727.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3990647641389728.\n",
      "['\"#下午茶#“总有一天 你会明白', ... ]\n",
      "计算所得距离系数： 41.976806.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "-------------------------------------------------------\n",
      "分析新闻编号： 17.\n",
      "该新闻内容如下：\n",
      "　　原标题：“史上最严”高考将临 多地部署严防大学生替考　　中新网北京6月5日电（记者 阚枫）2016年高考进入最后的倒计时，近期，从教育部到各地教育主管部门密集部署考试纪律，确保今年的高考安全。为了杜绝替考现象发生，多地出招严防大学生离校充当高考“枪手”。　　6月3日，教育部网站发出“教育部提醒考生诚信考试”的消息，提醒考生遵守考纪、拒绝作弊。　　这则消息中，教育部还附上了两条法条，一条来自去年11月开始实施的《刑法》（修正案九），一条来自本月起刚刚开始实施的新版《教育法》。　　临近2016年高考，一些媒体用“史上最严”来形容今年高考的严格。　　去年11月1日起正式实施的《刑法》（修正案九）明确，在法律规定的国家考试中，组织作弊的将入刑定罪，最高可处七年有期徒刑。“作弊入刑”后，即将迎来一场全国最大规模、最受关注的国家考试——高考。　　教育部在3日发出的消息中称，《刑法》（修正案九）有关组织考试作弊罪条款将首次适用于高考。教育部提醒广大考生，要诚信考试，自觉遵守考试纪律和考场规则，切勿轻信各种团伙和个人“助考”的蛊惑以致上当受骗，蒙受损失，抱憾终身。　　除了“作弊入刑”，本月刚刚开始实施的新版《教育法》明确了对考生考试作弊的惩处办法。根据法条，包括非法获取考试试题或者答案，携带或者使用考试作弊器材、资料，抄袭他人答案，让他人代替自己参加考试等行为，或将面临“禁考”3年的处罚。　　据了解，教育部已经要求各地教育部门开展“诚信高考”教育活动，在考生诚信承诺书、考生须知等材料中增加《刑法》（修正案九）和新修订《教育法》中涉考违法处罚条款的内容，让考生知晓考试舞弊所要承担的严重后果。　　资料图：5月25日，江苏扬州一所中学迎高考，校园内挂满了正能量励志横幅标语，高三年级教室中的黑板报上也写出了各种风趣个性的高考标语，祝福学子们拼搏成功。孟德龙 摄　　今年高考的“史上最严”，还能从教育部对于今年高考纪律的三令五申中观察。　　在教育部官网“教育要闻”一栏中，从5月25日至今，教育部在10天之内6次发出有关确保今年高考安全的消息。　　这些消息包括，教育部与各省签订2016年高考安全责任书；会同国家教育统一考试工作部际联席会议成员单位，分赴部分省份开展高考安全督查；召开2016年高考招生安全稳定工作视频会议；教育部和各省（区、市）开通2016年高考举报电话；教育部提醒考生诚信考试等。　　从更长的时间段观察，根据公开报道，记者不完全统计，从今年3月以来，教育部至少10次通过会议、文件、督查等方式部署高考纪律。　　早在今年3月，教育部发布的《关于做好2016年普通高校招生工作的通知》中就已明确，各地要综合治理考试环境，继续开展净化涉考网络环境、打击销售作弊器材、净化考点周边环境、打击替考作弊等专项行动。　　之后，教育部还印发了《2016年普通高等学校招生全国统一考试考务工作规定》，对今年高考试卷的印制、运送与保管、考试的实施、评卷等流程都进行了明确。　　值得一提的是，近期，北京警方就表示高考期间将启动高等级防控方案，首次动用特警完成试卷押运进京的任务。　　此外，据教育部介绍，从5月份开始，各地还陆续开展了“打击销售作弊器材”“净化涉考网络环境”“净化考点周边环境”“打击替考作弊”等4个专项行动。　　各地公安、工信、工商、教育等部门在中学、高校、通讯电子产品市场、考点周边及互联网上联合对非法招募替考“枪手”、组织助考活动、违法贩卖作弊器材、发布涉考不良信息等危害考试安全、扰乱考试秩序、谋取非法利益的行为进行了重点侦查，依法打掉了一批犯罪团伙。　　资料图：5月25日，江苏扬州一所中学迎高考，校园内挂满了正能量励志横幅标语，高三年级教室中的黑板报上也写出了各种风趣个性的高考标语，祝福学子们拼搏成功。孟德龙 摄　　根据教育部近日发布的消息，教育部对往年出现高考安全事件、考风考纪相对薄弱的省级教育部门和学校进行了约谈；对往年出现替考“枪手”较多的高校，专门下发通知，要求举一反三，严防再次出现大学生充当替考“枪手”的现象。　　去年高考，发生的江西南昌的“替考事件”震惊全国，多名涉案人员已经获刑。今年5月10日，江西省召开2016年普通高校招生考试安全工作电视电话会议，江西副省长殷美根在会上特别强调，要认真汲取去年“6•7”高考替考事件的深刻教训，高度警醒，引以为戒。　　观察今年各地对于高考安全的部署，严防“枪手”替考，成了保障今年高考安全的重要工作。　　例如，宁夏规定，本科高校高考期间将加强在校生管理，严格请假制度，逐一确认离校学生去向，严防出现充当替考“枪手”的现象。　　山东要求，高考期间各高等学校应坚持正常的教学活动，加强对学生的考勤管理，一般不允许请假，“对无故未到校者，要逐人查清去向，对去向可疑者，要深查细究，防止学生参与替考”。　　湖北也规定，高考期间各高校应坚持正常的教学活动，加强对在校生（含研究生）的考勤管理，原则上不允许学生请假。“对校园内张贴的组织替考和寻找“枪手”、售卖考试答案和作弊器材等涉考广告进行清理，如发现可疑人员和重要线索，要及时向领导报告，必要情况下向公安机关报案。”（完）只要认识到空无的道理，生命就无往而不胜。生命想透了其实与一个晚期癌症病人无异，什么都不必太过执着，喜欢干点什么事就干点什么事而已。“特朗普现象”其实是美国新教文明进入衰退期以后的一次自救。特朗普和他背后的美国群众，是对内外挑战的坚决应战，是美国文明不甘沉沦的生命活力迸发。而与之对立的建制派，则是腐朽的、堕落的。特朗普参选的结果，将决定美国未来是走向中兴还是就此沉沦。中国的科技教育体制需要进一步完善，对这一点大家有广泛共识。完善体制的重要举措之一就是支持年轻人，特别是那些独立生涯起步不久、相当于国外助理教授时期的年轻科学工作者，以及当代科学研究的主力军：博士后和研究生。从上个世纪80年代以来有越来越多国家的共产党与社会党开始不同程度的互相交往、联合斗争。中共自1982年以来也与社会党国际和多国社会党建立联系，甚至多次派代表以观察员身份参加社会党国际每隔三年召开一次的国际代表大会。Copyright ©1996-2016 SINA Corporation, All Rights Reserved\n",
      "\n",
      "总共匹配文章数： 0.\n",
      "以下是匹配列表：\n",
      "-------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "-------------------------------------------------------\n",
      "分析新闻编号： 18.\n",
      "该新闻内容如下：\n",
      "毛坦厂是安徽的一座僻静小镇，周围是沟壑丛生的山峦。可这座小镇却拥有一座大名鼎鼎的中学，它被称作“亚洲最大高考工厂”，拥有超高的升学率，每年都有很多家长慕名而来，将孩子送进这里学习，这里就是毛坦厂中学。每年高考前，这所学校都将会为高三考生举办出征仪式，近万名考生乘坐大巴浩浩荡荡地驶出校门，好不壮观。今年的出征仪式，新浪新闻将与您共同见证！人群已经散去，部分家长在路边合影留念。一年一度的万人送考大会，也缓缓落下帷幕。祝考生们在高考中发挥出自己应有的水平，因为考场外还有人在默默地为他们祈祷和祝愿。直播结束。谢谢大家的收看。左边这位家长的女儿今年就要参加高考。她从6年前就随孩子过来陪读，那时孩子还在读初中。当被问到孩子想考什么学校时，阿姨笑容满面：“当然是好学校呀。”一个考生，牵动的是一个家庭的心脏；一场考试，书写的是一个家庭的未来。愿考生们今年都能顺利发挥！大巴已经全部开出。现在跟在后面的，是一些送考的私家车。这所中学成为整个毛坦厂镇跳动的心脏。每个寒暑假，在没有学生的日子里，这个小镇安静的吓人，商店歇业，居民盖起的三层大楼大门紧闭空空荡荡。而一旦开学，这里便又是一片沸腾。考生们一手拿手机拍照，一手向送考家长们挥手。镇上没有KTV、网吧等容易让学生分心的娱乐场所，据说曾经的一家网吧被家长们抵制，赶走了。第16辆大巴开出，速度已经快出了许多。可以近距离地看到车上的考生。有位女生笑容灿烂，向车外的人群挥手致意，似乎看不出对即将到来的“独木桥”有丝毫紧张。因为聚集的送考家长很多，现场有保安在维持秩序。车上有位考生露出了“迷之微笑”，是否是因为胸有成竹呢？愿你考试顺利。许多家长专程从外地赶来。陪读的日子也是家长们的煎熬，每到高考时，都有一大波陪读家长庆幸终于熬到头了。但也有家长在孩子考上大学后依然留在这里做一些简单的工作维持生计。数据显示，2015年高考中，毛坦厂中学参考人数13000人，其中达一本分数线3106人，二本人数4896人，本科达线近11000人。应届一本达线率为41.01%，应届本科达线率为85.94%。每辆大巴车的副驾驶都坐了一位学校的老师，会向家长挥手致意。第五辆大巴车驶出，速度已经比之前几辆快了很多。以前有讲究送考车的头车司机要姓马或者属马，寓意马到成功。但在近两年，似乎并没有这么严苛。第四辆大巴开出。今年出征的大巴车比往年少了很多，据毛坦厂中学工作人员称，以前送考车最多达到70多辆大巴车，今年很多外地考生都坐着私家车先走了。第三辆大巴开出。Copyright © 1996-2016 SINA Corporation, All Rights Reserved\n",
      "\n",
      "总共匹配文章数： 10.\n",
      "以下是匹配列表：\n",
      "-------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3983002100422049.\n",
      "['【毛坦厂中学考生出征高考 场面壮观】毛坦厂是安徽的一座僻静小镇。这座小镇因一所被称作“亚洲最大高考工厂”的中学闻名。每年高考前，毛坦厂中学都会为高三考生举办出征仪式。今年毛坦厂中学用30辆大巴运送考生，头车尾号666，司机属马，寓意马道成功。又是一年送考时：http://t.cn/R55SBVG', ... ]\n",
      "计算所得距离系数： 101.150992.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3982915047729803.\n",
      "['【新浪新闻视频直播“亚洲最大高考工厂”出征仪式】毛坦厂是安徽的一座僻静小镇。这座小镇因一所被称作“亚洲最大高考工厂”的中学闻名。每年高考前，毛坦厂中学都会为高三考生举办出征仪式，近万名考生乘坐大巴浩浩荡荡地奔赴高考“前线”。新浪正视频直播今年的出征仪式，快来看http://t.cn/R5G6wCy', ... ]\n",
      "计算所得距离系数： 103.008626.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3982926468863661.\n",
      "['【新浪新闻视频直播“亚洲最大高考工厂”出征仪式】在毛坦厂中学校门外，万余名家长与居民夹道欢送今年的高考考生们奔赴“前线”，以至于当地需要出动警车为送考大巴开道。每辆大巴缓缓驶出时，路边的家长都卖力地挥舞手中的旗子，喊着加油的话语，不论车上是否有自己的孩子。更多精彩细节快来看<万人送考！新浪视频直...>', ... ]\n",
      "计算所得距离系数： 105.389977.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3983065195980853.\n",
      "['【围观毛坦厂中学“万人送考” 19辆大巴警车开道（组图）】6月5日上午8时，安徽六安毛坦厂中学万人送考，19辆大巴载着近千名高三学生从毛坦厂中学出发，前往六安市的高考考点，数千名学生家长和当地居民夹道相送。 http://t.cn/R55TLBc', ... ]\n",
      "计算所得距离系数： 107.574260.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3982931959580238.\n",
      "['【直播录像丨安徽毛坦厂中学：“高考工厂”考生出发，万人送考】5日8点08分，毛坦厂中学近30辆大巴车运送即将参加2016年高考的高三考生前往六安，近万名考生家长和各界人士在马路两边夹道欢送。该校成立于1939年，截至2015年11月，教职工780余人，教学班200多个，在校生近2万人。http://t.cn/R55wixJ', ... ]\n",
      "计算所得距离系数： 108.409638.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3983309173704499.\n",
      "['#新浪看见#【在“高考工厂”陪读是一段怎样的日子？】6月5日是毛坦厂镇一年一度的送考节，整个小镇万人空巷。这场比春节还要热闹的集会大部分由陪读家长组成。陪孩子漂泊备考的日子结束了，这一刻，轻松和忐忑都写在他们脸上。http://t.cn/R5tMFLo', ... ]\n",
      "计算所得距离系数： 110.239657.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3983475381590038.\n",
      "['航拍亚洲最大“高考工厂” 毛坦厂中学万名学生迎考！[吃惊]http://t.cn/R5tssAA （转）', ... ]\n",
      "计算所得距离系数： 111.072392.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3983460282254153.\n",
      "['#2016高考#对于即将到来的考试，周刊君想说的简单直接，戳图，祝各位考生好运！#高考加油#', ... ]\n",
      "计算所得距离系数： 111.587845.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3983693754451453.\n",
      "['#2016高考#【2016年广东高考语文作文题目来了↓↓】如果你是考生，准备怎么写？（羊城晚报高考直播团队）', ... ]\n",
      "计算所得距离系数： 111.732877.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "匹配微博： #3983692873581668.\n",
      "['#2016高考#【全国卷高考语文作文题目来了↓↓】如果你是考生，准备怎么写？（羊城晚报高考直播团队）', ... ]\n",
      "计算所得距离系数： 111.749480.\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "-------------------------------------------------------\n",
      "分析新闻编号： 20.\n",
      "该新闻内容如下：\n",
      "　　今天要说的这个故事，也许只有在电视剧里才会看到。今天，我找到了一对小夫妻，听他们说这段奇妙的缘分。　　5月29日，是新娘陆怡沁和新郎张何栋大喜的日子。在婚礼前一周的那个晚上，小两口正在家里整理儿时的照片，准备在婚礼那天投放到现场的大屏幕。　　当张何栋把16年前一张在景区拍的照片，扫描进电脑并放大的时候，一旁站着的陆怡沁大叫一声，还跳了起来：“老公，你背后的那个人，不是我妈妈吗？”　　这对新人是嘉兴人，新娘25岁，新郎30岁，都住在南湖区，两家其实离得很近，不过，在2015年3月份经朋友介绍下，男生女生才第一次认识。　　“第一次见到他，对他的印象有点呆呆的，但感觉人蛮好，很亲切，很自然，像是一家人感觉，就觉得可能要嫁的就是这个男人了。” 陆怡沁说，相熟后，两人相处的很不错，半年过去，就到了谈婚论嫁的阶段。　　陆怡沁本以为只是一场普通得不能再普通的恋情，相亲、相识、相熟、相知、相爱，约会、吃饭、逛街、看电影，谈得差不多了，两家人开始催着说，可以结婚了。　　“你让我现在回想当初谈恋爱的细节，我可能都不太记得，反正就是跟大多数的恋爱一样，很平静的爱着，经过一年多的相处，感觉互相之间的爱越来越深，然后就想着可以组个家庭了。”今年春节后，两人认真商量了一下结婚的事情，最终定下来，今年5月29日办婚礼。　　婚礼上，总要想一些浪漫，而且能感动客人的环节。夫妻俩想了很久，打算把两人从小到大的照片，尽可能多地找出来，在婚礼上还原彼此的童年和青春。　　婚礼前一个星期，当年的胶片照片找出来很多，张何栋开始一张张扫描进去，打算做一本电子画册，可以在婚礼现场播给客人看。　　扫描一张，两人就回忆一次当年的经历。　　“你看，这是我14岁的时候，那年是2000年，一家人赶流行，说是千禧年来了，去无锡灵山大佛祈福。你看我当年长的也挺帅吧。” 张何栋把这张有些泛黄的照片扫进电脑后，一边放大一边跟陆怡沁说。　　陆怡沁没看16年前的老公，倒是照片中，一个穿红衣服的女人让她凑近去看。　　这张照片里的红衣女子，就是张何栋的丈母娘。　　“再放大一看，我就大声叫了起来，我的妈呀！老公还说干嘛这么大惊小怪，我说，这真的是我妈妈呀。” 陆怡沁说，当时自己还蹦了起来，说妈妈怎么会出现在照片里？　　因为要收拾新房子，陆怡沁的妈妈当时也在新家，她就叫妈妈一起来看。　　妈妈觉得不可思议，一直说：“这怎么可能啊，哪有这么巧的事情。”　　可是，再看看，妈妈说这个人真的是自己，而且那年一家人也确实去过同一个景区，家里也留着这张照片。　　陆怡沁的妈妈回忆了一下日子，虽然不记得是几月几日，但确定是当年的大年初五。　　陆怡沁回到娘家，翻出来了那天拍的照片，同样的衣服，同样的地方，什么都对上了。　　而更巧的是，两家除了都留着照片，连当天入景区的门票也都一直珍藏着。　　张何栋说，也不知道为什么，他的爸爸一直把门票放在钱包里，16年来，钱包换了好几个，门票却一直都在。　　“原来我这16年，等的就是你呀。”被这两张照片有些搞懵了的张何栋，一把抱住了陆怡沁。　　“超级不可思议啊，要不是有照片为证，我都以为这是编故事。现在我特相信缘分了，冥冥中就注定了。”陆怡沁马上给婚礼的司仪打电话，说一定要把这个故事，讲给当晚的每一位客人听。　　那天晚上，陆怡沁通过电子邮件，把照片发给了司仪。　　婚礼那天，司仪讲完照片的故事，完成所有流程后，偷偷跑过来为这对新人：“你们这照片不是PS的吧，我做了9年婚礼司仪了，还是第一次碰到。”　　不光司仪不信，当晚听到这个故事的所有客人也觉得好神奇。婚礼结束后，陆怡沁的微信里收到了好多朋友发来求证的信息，都是来问照片是真是假。　　那天的婚礼，主题是亲情。“老公说，虽然那时候彼此都不认识，但老天一定是已经给我们安排了16年后的事情，所以其实亲情早已经等着我们了，有了这样妙不可言的缘分，以后会更加珍惜这份感情。”　　婚礼忙完了，夫妻俩也已经订好了6月7日去欧洲旅行的机票。　　“我们打算去法国、瑞士，这两个都是浪漫的国家，我一直以为自己和老公都不是浪漫的人，但估计照片会改变我们的想法的。”陆怡沁说，这次出去旅 游，他们还要在飞机上，在旅途中，边走边说各自的往事，“说不定在某一年嘉兴的街头，我们也曾出现在同一个场合，说不定我们还会有更多不可思议的交集 呢。”　　陆怡沁在跟我讲这个故事的时候，我能听出来，她的声音是激动的，还有一些兴奋。　　在采访结束的时候，我跟陆怡沁说，等报纸出来了，我会给她寄一份过去，她把这么美好的故事分享给快报，我就把报纸当一份礼物祝他们新婚快乐。　　“真的吗？那这份礼物就太珍贵了，我一定会好好保存起来，以后讲给我们的孩子听。” 陆怡沁说。\n",
      "\n",
      "总共匹配文章数： 0.\n",
      "以下是匹配列表：\n",
      "-------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(test)):\n",
    "    print \"\"\n",
    "    print \"+++++++++++++++++++++++++++++++++++++++++++++++++++++++\"\n",
    "    print \"-------------------------------------------------------\"\n",
    "    print \"分析新闻编号： %s.\" % test['id'][i]\n",
    "    print \"该新闻内容如下：\"\n",
    "    print test['text'][i]\n",
    "    print \"\"\n",
    "    print \"总共匹配文章数： %d.\" % len(test['assign_weibos'][i])\n",
    "    print \"以下是匹配列表：\"\n",
    "    print \"-------------------------------------------------------\"\n",
    "    for ii in range(len(test['assign_weibos'][i])):\n",
    "        print \"--------------------------------------------------------\"\n",
    "        print \"匹配微博： #%d.\" % test['assign_weibos'][i][ii]['id']\n",
    "        print weibos[weibos['id'] == test['assign_weibos'][i][ii]['id']]['text']\n",
    "        print \"计算所得距离系数： %f.\" % test['assign_weibos'][i][ii]['similarity']\n",
    "        print \"--------------------------------------------------------\"\n",
    "    print \"--------------------------------------------------------\"\n",
    "    print \"++++++++++++++++++++++++++++++++++++++++++++++++++++++++\"\n",
    "    print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
